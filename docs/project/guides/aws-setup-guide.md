# Guide AWS - Configuration S3 et D√©ploiement EMR (D√©butant)

**Version :** 2.0 - Guide Ultra-D√©taill√© pour D√©butant AWS
**Date :** 6 octobre 2025
**Objectif :** Guide pas-√†-pas ULTRA-PR√âCIS pour configurer AWS et ex√©cuter le notebook EMR
**Public :** D√©butant AWS n'ayant jamais utilis√© AWS auparavant

---

## Important √† Savoir AVANT de Commencer

### WARNINGS CRITIQUES

1. **NE PAS OUBLIER DE TERMINER LE CLUSTER EMR** √† la fin ‚Üí Sinon co√ªts continuent !
2. **TOUJOURS v√©rifier que vous √™tes en r√©gion eu-west-1** (coin haut droit AWS Console)
3. **Configurer les alertes budget** AVANT de cr√©er quoi que ce soit
4. **Sauvegarder le fichier .pem** (cl√© SSH) dans un endroit s√ªr (`~/.ssh/`)

### Budget et Co√ªts

- **Budget maximum :** 10‚Ç¨
- **Co√ªts estim√©s r√©els :** ~1.69‚Ç¨
- **Marge de s√©curit√© :** 8.31‚Ç¨ (83%)

### Temps Estim√© Total : ~6 heures

| Phase | Dur√©e | Travail Actif | Attente | Quand faire |
|-------|-------|---------------|---------|-------------|
| Phase 0 : Config initiale | 30 min | 30 min | 0 | Maintenant |
| Phase 1 : S3 + Upload | 2h | 30 min | 1h30 | Lancer upload et faire autre chose |
| Phase 2 : EMR | 1h | 45 min | 15 min | Attendre d√©marrage cluster |
| Phase 3 : JupyterHub | 15 min | 15 min | 0 | Connexion rapide |
| Phase 4 : Ex√©cution | 2h | 15 min | 1h45 | Lancer pipeline et faire autre chose |
| Phase 5 : Validation | 30 min | 30 min | 0 | V√©rifier et TERMINER cluster |
| **TOTAL** | **~6h** | **~3h** | **~3h** | **Peut √™tre fait sur 1-2 jours** |

üí° **Astuce :** Vous pouvez faire autre chose pendant l'upload dataset et l'ex√©cution du notebook

---

## Pr√©requis - V√©rification

### Compte AWS

- [ ] Compte AWS cr√©√© sur https://aws.amazon.com
- [ ] Email de confirmation AWS re√ßu
- [ ] Carte bancaire enregistr√©e et valid√©e
- [ ] Vous pouvez vous connecter √† https://console.aws.amazon.com

### ‚úÖ Environnement Local

- [ ] macOS (vous utilisez un Mac)
- [ ] Terminal accessible : Applications ‚Üí Utilitaires ‚Üí Terminal
- [ ] Navigateur : Chrome ou Firefox (recommand√©)

### ‚úÖ Fichiers du Projet

- [ ] Dataset Fruits-360 dans `/Users/maximenejad/Developer/OPC/P9/data/raw/fruits-360_dataset/`
- [ ] Notebook PySpark dans `/Users/maximenejad/Developer/OPC/P9/notebook/P8_Notebook_Linux_EMR_PySpark_V1.0.ipynb`

---

## PHASE 0 : Configuration Initiale AWS (30 minutes)

### √âtape 0.1 : Premi√®re Connexion √† AWS Console

**üìç CE QUE VOUS ALLEZ FAIRE :** Se connecter √† AWS et s√©lectionner la bonne r√©gion

1. **Ouvrir votre navigateur** (Chrome ou Firefox)
2. **Aller sur :** https://console.aws.amazon.com
3. **Se connecter avec :**
   - Email de votre compte AWS
   - Mot de passe

**‚úÖ VOUS DEVEZ VOIR :** Page d'accueil AWS Console avec :
- Barre noire en haut
- Votre nom en haut √† droite
- Barre de recherche au centre
- Plein de carr√©s avec des ic√¥nes (services AWS)

---

### √âtape 0.2 : S√©lection R√©gion eu-west-1 (RGPD - OBLIGATOIRE)

**üìç ULTRA IMPORTANT - √Ä V√âRIFIER √Ä CHAQUE CONNEXION AWS**

1. **Regarder en HAUT √Ä DROITE** de la page (√† c√¥t√© de votre nom)
2. **Vous voyez un nom de r√©gion** avec un drapeau
   - Exemples possibles : "N. Virginia", "Paris", "Ohio", etc.
3. **Cliquer sur ce nom de r√©gion**
4. **Une liste d√©roulante appara√Æt** avec toutes les r√©gions AWS
5. **Descendre et CHERCHER :** `Europe (Ireland) eu-west-1`
6. **CLIQUER sur :** `Europe (Ireland) eu-west-1`

**‚úÖ VOUS DEVEZ VOIR :** En haut √† droite :
- Drapeau de l'Irlande üáÆüá™
- Texte : "Europe (Ireland) eu-west-1" ou juste "eu-west-1"

‚ö†Ô∏è **CRITIQUE :** V√©rifier TOUJOURS que vous √™tes en `eu-west-1` avant CHAQUE action AWS !
**Pourquoi ?** RGPD - Donn√©es doivent rester en Europe

---

### √âtape 0.3 : Cr√©er Alerte Budget (S√©curit√© Anti-D√©passement)

**üìç CE QUE VOUS ALLEZ FAIRE :** Recevoir des emails quand vous approchez 5‚Ç¨, 8‚Ç¨ ou 10‚Ç¨

#### Partie A : Acc√©der au service Budgets

1. **Dans la barre de recherche** (en haut, au milieu de l'√©cran) :
   - Cliquer dans la barre
   - Taper : `Budgets`
   - **Attendre 1 seconde** ‚Üí Des r√©sultats apparaissent

2. **Dans les r√©sultats** :
   - Chercher la ligne "AWS Budgets" (avec ic√¥ne de calculatrice)
   - Cliquer dessus

**‚úÖ VOUS DEVEZ VOIR :**
- Page "AWS Budgets"
- Bouton orange "Create budget" en haut √† droite

#### Partie B : Cr√©er le budget avec 3 alertes

3. **Cliquer sur "Create budget"** (bouton orange)

4. **Page "Select budget type" :**
   - **Vous voyez plusieurs options** (Cost, Usage, etc.)
   - **V√©rifier que "Cost budget" est coch√©** (normalement oui par d√©faut)
   - **Cliquer sur "Next"** (bouton orange en bas √† droite)

5. **Page "Set budget amount" :**
   Remplir les champs suivants :

   - **Budget name :**
     - Cliquer dans le champ
     - Taper : `P9-Fruits-Budget`

   - **Period :**
     - Cliquer sur le menu d√©roulant
     - S√©lectionner : **"Monthly"**

   - **Budgeting method :**
     - S√©lectionner : **"Fixed"**

   - **Enter your budgeted amount ($) :**
     - Cliquer dans le champ
     - Taper : `10`
     - ‚ö†Ô∏è Note : M√™me si compte en EUR, AWS affiche USD. 10 USD ‚âà 10 EUR

   - **Cliquer sur "Next"** (bas de page)

6. **Page "Configure alerts" :**

   **ALERTE 1 - √Ä 5‚Ç¨ (50%) :**
   - Cliquer sur bouton **"Add an alert threshold"**
   - **Threshold :** Taper `5`
   - **Email recipients :** Taper votre adresse email
   - Cliquer √† nouveau sur **"Add an alert threshold"** (pour ajouter alerte 2)

   **ALERTE 2 - √Ä 8‚Ç¨ (80%) :**
   - **Threshold :** Taper `8`
   - **Email recipients :** (d√©j√† rempli avec votre email)
   - Cliquer une 3√®me fois sur **"Add an alert threshold"**

   **ALERTE 3 - √Ä 10‚Ç¨ (100%) :**
   - **Threshold :** Taper `10`
   - **Email recipients :** (d√©j√† rempli)

   - **Cliquer sur "Next"**

7. **Page "Attach actions" (OPTIONNEL) :**
   - Vous pouvez ignorer cette page
   - **Cliquer sur "Next"**

8. **Page "Review" :**
   - **V√©rifier que tout est correct :**
     - Budget name : P9-Fruits-Budget
     - Amount : $10
     - 3 alertes : $5, $8, $10
   - **Cliquer sur "Create budget"** (bouton orange)

**‚úÖ VOUS DEVEZ VOIR :**
- Message vert en haut : "Budget P9-Fruits-Budget created successfully"
- Votre budget appara√Æt dans la liste

**üìß R√âSULTAT :**
- Vous recevrez 3 emails de confirmation d'AWS
- Vous recevrez ensuite un email chaque fois que vous d√©pensez 5‚Ç¨, 8‚Ç¨ ou 10‚Ç¨

---

### √âtape 0.4 : Cr√©er R√¥les IAM (Permissions)

**üìç CE QUE VOUS ALLEZ FAIRE :** Cr√©er 2 "r√¥les" (= permissions) pour permettre √† EMR d'utiliser S3

#### Partie A : Acc√©der √† IAM

1. **Dans la barre de recherche** (en haut), taper : `IAM`
2. **Cliquer sur "IAM"** dans les r√©sultats

**‚úÖ VOUS DEVEZ VOIR :**
- Page "IAM Dashboard"
- Menu √† gauche avec plein d'options
- Panneau central avec des statistiques

#### Partie B : Cr√©er le 1er R√¥le (Pour le Service EMR)

3. **Dans le menu de GAUCHE**, chercher et cliquer sur **"Roles"**

**‚úÖ VOUS DEVEZ VOIR :**
- Page "Roles"
- Liste de r√¥les (peut √™tre vide si nouveau compte)
- Bouton orange "Create role" en haut √† droite

4. **Cliquer sur "Create role"** (bouton orange)

5. **Page "Select trusted entity" :**

   - **Trusted entity type :**
     - V√©rifier que **"AWS service"** est s√©lectionn√© (normalement oui)

   - **Use case :**
     - Vous voyez une liste d√©roulante avec EC2, Lambda, etc.
     - **Chercher dans la liste : "EMR"**
     - **Cliquer sur "EMR"**
     - Puis en dessous, **s√©lectionner "EMR"** (PAS "EMR Notebooks" ni "EMR Serverless")

   - **Cliquer sur "Next"**

6. **Page "Add permissions" :**

   - Vous voyez une **barre de recherche** et une liste de "policies"

   **Ajouter la 1√®re permission :**
   - Dans la barre de recherche, taper : `AmazonEMRServicePolicy_v2`
   - Dans les r√©sultats, **cocher la case** √† c√¥t√© de `AmazonEMRServicePolicy_v2`

   **Ajouter la 2√®me permission :**
   - **Effacer** la barre de recherche
   - Taper : `AmazonS3FullAccess`
   - **Cocher la case** √† c√¥t√© de `AmazonS3FullAccess`

   **‚úÖ V√âRIFICATION :** Vous devez avoir 2 policies coch√©es :
   - AmazonEMRServicePolicy_v2
   - AmazonS3FullAccess

   - **Cliquer sur "Next"**

7. **Page "Name, review, and create" :**

   - **Role name :**
     - Cliquer dans le champ
     - Taper EXACTEMENT : `EMR_DefaultRole_P9`
     - ‚ö†Ô∏è Important : Respecter majuscules/minuscules et underscores

   - **Description (optionnel) :**
     - Taper : `Role for EMR cluster P9 project`

   - **Descendre en bas de la page**
   - **Cliquer sur "Create role"** (bouton orange)

**‚úÖ VOUS DEVEZ VOIR :**
- Message vert : "Role EMR_DefaultRole_P9 created successfully"
- Vous √™tes de retour sur la page "Roles"
- Le r√¥le `EMR_DefaultRole_P9` appara√Æt dans la liste

#### Partie C : Cr√©er le 2√®me R√¥le (Pour les Instances EC2 d'EMR)

8. **Cliquer √† nouveau sur "Create role"** (bouton orange en haut)

9. **Page "Select trusted entity" :**

   - **Trusted entity type :** **"AWS service"** (d√©j√† s√©lectionn√©)

   - **Use case :**
     - Chercher dans la liste : **"EC2"**
     - **Cliquer sur "EC2"**

   - **Cliquer sur "Next"**

10. **Page "Add permissions" :**

    **Ajouter la 1√®re permission :**
    - Dans la barre de recherche, taper : `AmazonS3FullAccess`
    - **Cocher** `AmazonS3FullAccess`

    **Ajouter la 2√®me permission :**
    - Effacer la barre et taper : `AmazonElasticMapReduceforEC2Role`
    - **Cocher** `AmazonElasticMapReduceforEC2Role`

    **‚úÖ V√âRIFICATION :** 2 policies coch√©es :
    - AmazonS3FullAccess
    - AmazonElasticMapReduceforEC2Role

    - **Cliquer sur "Next"**

11. **Page "Name, review, and create" :**

    - **Role name :** Taper EXACTEMENT : `EMR_EC2_DefaultRole_P9`
    - **Description :** `Role for EMR EC2 instances P9`
    - **Cliquer sur "Create role"**

**‚úÖ VOUS DEVEZ VOIR :**
- Message vert : "Role EMR_EC2_DefaultRole_P9 created successfully"
- Dans la liste des r√¥les, vous avez maintenant :
  - `EMR_DefaultRole_P9`
  - `EMR_EC2_DefaultRole_P9`

**üìå PHASE 0 TERMIN√âE !**
- ‚úÖ Budget avec 3 alertes configur√©
- ‚úÖ 2 r√¥les IAM cr√©√©s
- ‚úÖ R√©gion eu-west-1 s√©lectionn√©e

**‚è∏Ô∏è PAUSE POSSIBLE :** Vous pouvez faire une pause ici et revenir plus tard

---

## PHASE 1 : Cr√©ation Bucket S3 et Upload Dataset (2 heures)

**‚è±Ô∏è Temps actif : 30 min | Temps attente : 1h30 (upload)**

### √âtape 1.1 : Cr√©er le Bucket S3

**üìç CE QUE VOUS ALLEZ FAIRE :** Cr√©er un "bucket" (= dossier cloud) pour stocker vos donn√©es

#### Partie A : Acc√©der √† S3

1. **V√©rifier r√©gion :** En haut √† droite ‚Üí doit afficher **eu-west-1** ‚ö†Ô∏è
2. **Barre de recherche** (en haut) : Taper `S3`
3. **Cliquer sur "S3"** dans les r√©sultats

**‚úÖ VOUS DEVEZ VOIR :**
- Page "Amazon S3"
- Texte "Buckets" √† gauche
- Bouton orange "Create bucket" √† droite

#### Partie B : Cr√©er le bucket

4. **Cliquer sur "Create bucket"** (bouton orange)

5. **Page "Create bucket" - Remplir les champs :**

   **General configuration :**

   - **Bucket name :**
     - Taper : `fruits-classification-p9-maxime`
     - ‚ö†Ô∏è Remplacer "maxime" par VOTRE pr√©nom (en minuscules)
     - ‚ö†Ô∏è Le nom doit √™tre UNIQUE au monde (AWS dira si d√©j√† pris)
     - Exemples valides : `fruits-classification-p9-john`, `fruits-classification-p9-marie`

   - **AWS Region :**
     - **V√âRIFIER que c'est bien :** `EU (Ireland) eu-west-1`
     - ‚ö†Ô∏è Si ce n'est pas eu-west-1, cliquer sur le menu d√©roulant et s√©lectionner `EU (Ireland) eu-west-1`

   **Object Ownership :**
   - Laisser **"ACLs disabled (recommended)"** (d√©j√† s√©lectionn√©)

   **Block Public Access settings for this bucket :**
   - **IMPORTANT :** V√©rifier que **"Block all public access"** est COCH√â ‚úÖ
   - (S√©curit√© : emp√™che acc√®s public √† vos donn√©es)

   **Bucket Versioning :**
   - Laisser **"Disable"** (√©conomie de co√ªts)

   **Encryption :**
   - Laisser **"Server-side encryption with Amazon S3 managed keys (SSE-S3)"** (d√©j√† s√©lectionn√©)

   **Descendre en bas de la page**

   - **Cliquer sur "Create bucket"** (bouton orange)

**‚úÖ VOUS DEVEZ VOIR :**
- Message vert : "Successfully created bucket fruits-classification-p9-maxime"
- Votre bucket appara√Æt dans la liste des buckets

---

### √âtape 1.2 : Cr√©er la Structure de Dossiers dans S3

**üìç CE QUE VOUS ALLEZ FAIRE :** Cr√©er 3 dossiers : dataset, notebooks, results

1. **Dans la liste des buckets**, **cliquer sur le nom de votre bucket** : `fruits-classification-p9-maxime`

**‚úÖ VOUS DEVEZ VOIR :**
- Page du bucket (vide pour l'instant)
- Boutons en haut : "Upload", "Create folder", etc.

#### Cr√©er le dossier "Test" (donn√©es d'entr√©e)

2. **Cliquer sur "Create folder"**
3. **Folder name :** Taper `Test`
4. **Cliquer sur "Create folder"** (bouton orange en bas)

**‚úÖ VOUS DEVEZ VOIR :**
- Message vert : "Successfully created folder Test/"
- Dossier "Test/" appara√Æt dans la liste

#### Cr√©er le dossier "Results" (donn√©es de sortie)

5. **Cliquer sur "Create folder"** (√† nouveau)
6. **Folder name :** Taper `Results`
7. **Cliquer sur "Create folder"**

**‚úÖ V√âRIFICATION FINALE :** Structure cr√©√©e :
```
fruits-classification-p9-maxime/
‚îú‚îÄ‚îÄ Test/
‚îî‚îÄ‚îÄ Results/
```

8. **Revenir √† la racine du bucket :**
    - En haut de la page, cliquer sur le nom du bucket : `fruits-classification-p9-maxime`

---

### √âtape 1.3 : Installer et Configurer AWS CLI (Pour Upload Dataset)

**üìç CE QUE VOUS ALLEZ FAIRE :** Installer l'outil ligne de commande AWS pour uploader rapidement les 87k images

#### Partie A : Installer AWS CLI sur Mac

1. **Ouvrir Terminal** : Applications ‚Üí Utilitaires ‚Üí Terminal

2. **V√©rifier si AWS CLI d√©j√† install√© :**
   ```bash
   aws --version
   ```

   **Si vous voyez :** `aws-cli/2.x.x` ‚Üí AWS CLI d√©j√† install√©, passez √† Partie B

   **Si vous voyez :** `command not found` ‚Üí Continuer ci-dessous

3. **Installer AWS CLI avec Homebrew :**
   ```bash
   # Si vous n'avez pas Homebrew, l'installer d'abord :
   /bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

   # Puis installer AWS CLI :
   brew install awscli
   ```

   ‚è±Ô∏è Attendre 2-3 minutes

4. **V√©rifier installation :**
   ```bash
   aws --version
   ```

   **‚úÖ VOUS DEVEZ VOIR :** `aws-cli/2.x.x Python/3.x.x Darwin/...`

#### Partie B : Obtenir vos Access Keys AWS

**üìç CE QU'IL VOUS FAUT :** 2 cl√©s pour que AWS CLI puisse acc√©der √† votre compte

1. **Retourner dans AWS Console** (navigateur)

2. **En haut √† DROITE**, cliquer sur **votre nom de compte**
   - Un menu d√©roulant appara√Æt

3. **Cliquer sur "Security credentials"**

**‚úÖ VOUS DEVEZ VOIR :**
- Page "My Security Credentials"
- Section "Access keys"

4. **Descendre jusqu'√† la section "Access keys"**

5. **Cliquer sur "Create access key"** (bouton orange)

6. **Page "Access key best practices & alternatives" :**
   - S√©lectionner : **"Command Line Interface (CLI)"**
   - **Cocher** la case : "I understand the above recommendation..."
   - **Cliquer sur "Next"**

7. **Page "Set description tag" (optionnel) :**
   - Description : Taper `P9 Project CLI Access`
   - **Cliquer sur "Create access key"**

8. **Page "Retrieve access keys" - IMPORTANT :**

   **‚úÖ VOUS DEVEZ VOIR :**
   - **Access key** : Quelque chose comme `AKIAIOSFODNN7EXAMPLE`
   - **Secret access key** : Quelque chose comme `wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY`

   ‚ö†Ô∏è **CRITIQUE :** Ces cl√©s ne seront affich√©es qu'UNE SEULE FOIS !

   **FAIRE IMM√âDIATEMENT :**
   - **Cliquer sur "Download .csv file"** ‚Üí Sauvegarder sur votre Mac
   - OU **noter les cl√©s** quelque part de s√ªr (TextEdit, Notes, etc.)

   - **Cliquer sur "Done"**

#### Partie C : Configurer AWS CLI

9. **Retourner dans Terminal**

10. **Configurer AWS CLI :**
    ```bash
    aws configure
    ```

11. **AWS CLI va vous poser 4 questions - R√©pondre :**

    ```
    AWS Access Key ID [None]: [COLLER votre Access Key]
    AWS Secret Access Key [None]: [COLLER votre Secret Access Key]
    Default region name [None]: eu-west-1
    Default output format [None]: json
    ```

    **Appuyer sur ENTR√âE apr√®s chaque ligne**

**‚úÖ VOUS DEVEZ VOIR :** Le curseur revient (pas de message d'erreur = OK)

12. **Tester la configuration :**
    ```bash
    aws s3 ls
    ```

    **‚úÖ VOUS DEVEZ VOIR :**
    - La liste de vos buckets S3
    - Au minimum : `fruits-classification-p9-maxime`

**Si vous voyez une erreur :** V√©rifier que vous avez bien copi√© les 2 cl√©s

---

### √âtape 1.4 : Uploader le Dataset sur S3 (1-2 heures)

**üìç CE QUE VOUS ALLEZ FAIRE :** Uploader les 67 000 images (~2GB) sur S3

**‚ö†Ô∏è IMPORTANT :** Cette √©tape prend 1-2 heures. Vous pouvez lancer l'upload et faire autre chose.

#### Option A : Upload via AWS CLI (RECOMMAND√â - Plus rapide)

1. **Dans Terminal, aller dans le dossier du projet :**
   ```bash
   cd /Users/maximenejad/Developer/OPC/P9
   ```

2. **V√©rifier que le dataset existe :**
   ```bash
   ls -la data/raw/fruits-360_dataset/fruits-360/Training/ | head
   ```

   **‚úÖ VOUS DEVEZ VOIR :** Liste de dossiers (Apple Braeburn 1, Apple Crimson Snow, etc.)

3. **Uploader le dataset Training sur S3 :**

   **‚ö†Ô∏è Remplacer "maxime" par VOTRE pr√©nom dans la commande ci-dessous :**

   ```bash
   aws s3 sync ./data/raw/fruits-360_dataset/fruits-360/Training/ \
     s3://fruits-classification-p9-maxime/Test/ \
     --region eu-west-1
   ```

   **Appuyer sur ENTR√âE**

**‚úÖ VOUS DEVEZ VOIR :**
- Plein de lignes d√©filent : `upload: ...` avec noms de fichiers
- Exemple : `upload: data/raw/.../Apple_Braeburn_1/0_100.jpg to s3://...`

‚è±Ô∏è **TEMPS D'ATTENTE : 30-60 minutes**

üí° **ASTUCE :** Vous pouvez faire autre chose pendant ce temps. Laissez le Terminal ouvert et actif.

4. **Quand l'upload est termin√© :**

   **‚úÖ VOUS DEVEZ VOIR :** Le curseur revient (plus de lignes qui d√©filent)

5. **V√©rifier que l'upload a fonctionn√© :**
   ```bash
   aws s3 ls s3://fruits-classification-p9-maxime/Test/ --recursive | wc -l
   ```

   **‚úÖ VOUS DEVEZ VOIR :** Un nombre proche de `67000` (nombre d'images Training)

**F√âLICITATIONS !** Dataset upload√© sur S3 ‚úÖ

#### Option B : Upload via AWS Console (Plus lent - 2-3 heures)

**Si AWS CLI ne fonctionne pas, utiliser l'interface web :**

1. **AWS Console ‚Üí S3 ‚Üí Votre bucket ‚Üí Test/**
2. **Cliquer "Upload"**
3. **Cliquer "Add folder"**
4. **S√©lectionner :** `data/raw/fruits-360_dataset/fruits-360/Training`
5. **Cliquer "Upload"**
6. ‚è±Ô∏è Attendre 2-3 heures

---

**üìå PHASE 1 TERMIN√âE !**
- ‚úÖ Bucket S3 cr√©√© dans eu-west-1
- ‚úÖ Structure de dossiers cr√©√©e
- ‚úÖ Dataset upload√© sur S3 (67k images)
- ‚úÖ AWS CLI configur√©

**‚è∏Ô∏è PAUSE RECOMMAND√âE :** Bon moment pour faire une pause (30 min - 1 jour)

---

## PHASE 2 : Cr√©ation Cluster EMR (1 heure)

**‚è±Ô∏è Temps actif : 45 min | Temps attente : 15 min (d√©marrage cluster)**

### √âtape 2.1 : Cr√©er le Cluster EMR

**üìç CE QUE VOUS ALLEZ FAIRE :** Cr√©er un "cluster" (= plusieurs ordinateurs) pour faire les calculs Big Data

#### Partie A : Acc√©der au service EMR

1. **V√©rifier r√©gion :** En haut √† droite ‚Üí **eu-west-1** ‚ö†Ô∏è
2. **Barre de recherche** : Taper `EMR`
3. **Cliquer sur "EMR"**

**‚úÖ VOUS DEVEZ VOIR :**
- Page "Amazon EMR"
- Texte "Clusters" √† gauche
- Bouton orange "Create cluster" √† droite

4. **Cliquer sur "Create cluster"**

#### Partie B : Configuration du Cluster - SOFTWARE

**‚úÖ VOUS DEVEZ VOIR :** Page "Create Cluster" avec plein d'options

5. **Section "General Configuration" :**

   - **Cluster name :**
     - Taper : `Fruits-Classification-P9-Cluster`

   - **Amazon EMR release :**
     - Dans le menu d√©roulant, s√©lectionner : **emr-6.15.0** (ou derni√®re version 6.x)

6. **Section "Application bundle" :**

   - **S√©lectionner : "Custom"**

   - **Dans la liste des applications, COCHER :**
     - ‚úÖ **Spark**
     - ‚úÖ **JupyterEnterpriseGateway**
     - ‚úÖ **Hadoop**

   - **NE PAS cocher :** Hive, Presto, etc. (pas n√©cessaires)

#### Partie C : Configuration du Cluster - HARDWARE

7. **Section "Cluster configuration" :**

   **Instance groups (Uniform instance groups) - Laisser s√©lectionn√©**

   **Primary (Master) node :**
   - **Instance type :**
     - Cliquer sur le menu d√©roulant
     - Chercher : `m6g.xlarge` (ou `m5.xlarge` si m6g pas disponible)
     - S√©lectionner : **m6g.xlarge**

   - **Instance count :** `1` (d√©j√† rempli)

   - **Instance purchasing option :**
     - **S√©lectionner : "Spot"** ‚ö†Ô∏è IMPORTANT (√©conomise 70-90%)

   **Core nodes :**
   - **Instance type :**
     - S√©lectionner : **m6g.large** (ou `m5.large`)

   - **Instance count :** `2`

   - **Instance purchasing option :**
     - **S√©lectionner : "Spot"** ‚ö†Ô∏è IMPORTANT

**üí∞ V√âRIFICATION CO√õTS :**
- En haut de la page, vous devriez voir : "Estimated cost: $X.XX/hour"
- Doit √™tre environ : **$0.35-0.40/hour** (avec Spot)
- Pour 3 heures : ~1‚Ç¨

#### Partie D : Configuration - NETWORKING

8. **Section "Networking" :**

   - **Amazon VPC :**
     - Laisser : **"Default VPC"** (d√©j√† s√©lectionn√©)

   - **Subnet :**
     - Laisser : (n'importe quel subnet eu-west-1a, b ou c)

9. **Section "Cluster termination and node replacement" :**

   - **Termination protection :**
     - **D√âCOCHER** ‚ùå (Important pour pouvoir terminer le cluster)

   - **Cluster auto-termination :**
     - **COCHER** ‚úÖ "Use cluster auto-termination"
     - **Idle time :** Taper `3` (heures)
     - *(Le cluster s'√©teindra automatiquement apr√®s 3h d'inactivit√©)*

#### Partie E : Configuration - SECURITY

10. **Section "Security configuration and EC2 key pair" :**

    **EC2 key pair :**

    **Option 1 : Cr√©er une nouvelle cl√© (RECOMMAND√â) :**
    - Cliquer sur **"Create new EC2 key pair"** (lien bleu)
    - **Une nouvelle fen√™tre s'ouvre**
    - **Key pair name :** Taper `emr-p9-keypair`
    - **Key pair type :** Laisser **RSA**
    - **Private key file format :** Laisser **.pem**
    - **Cliquer sur "Create key pair"**
    - **‚ö†Ô∏è IMPORTANT :** Le fichier `emr-p9-keypair.pem` se t√©l√©charge
    - **SAUVEGARDER ce fichier** dans `~/.ssh/` sur votre Mac :
      ```bash
      # Dans Terminal :
      mv ~/Downloads/emr-p9-keypair.pem ~/.ssh/
      chmod 400 ~/.ssh/emr-p9-keypair.pem
      ```
    - **Retourner dans la fen√™tre AWS** (l'autre onglet)
    - **Rafra√Æchir la liste** : Cliquer sur l'ic√¥ne "rafra√Æchir" √† c√¥t√© du menu
    - **S√©lectionner :** `emr-p9-keypair`

    **Option 2 : S√©lectionner une cl√© existante (si vous en avez d√©j√†) :**
    - Dans le menu d√©roulant, s√©lectionner votre cl√© existante

11. **Section "Identity and Access Management (IAM) roles" :**

    - **Amazon EMR service role :**
      - Dans le menu d√©roulant, chercher et s√©lectionner : **EMR_DefaultRole_P9**

    - **EC2 instance profile for Amazon EMR :**
      - Dans le menu d√©roulant, chercher et s√©lectionner : **EMR_EC2_DefaultRole_P9**

**‚úÖ V√âRIFICATION AVANT CR√âATION :**
- Cluster name : Fruits-Classification-P9-Cluster
- EMR release : emr-6.15.0
- Applications : Spark, JupyterEnterpriseGateway, Hadoop
- Master : 1x m6g.xlarge Spot
- Core : 2x m6g.large Spot
- Termination protection : OFF
- Auto-termination : 3 hours
- EC2 key pair : emr-p9-keypair
- IAM roles : EMR_DefaultRole_P9 et EMR_EC2_DefaultRole_P9

#### Partie F : Lancer la Cr√©ation

12. **Descendre en BAS de la page**

13. **Cliquer sur "Create cluster"** (bouton orange)

**‚úÖ VOUS DEVEZ VOIR :**
- Vous √™tes redirig√© vers la page du cluster
- **Status : "Starting"** (en orange)

‚è±Ô∏è **ATTENDRE 10-15 minutes** pour que le cluster d√©marre

**Statuts successifs :**
- Starting (5 min)
- Bootstrapping (5 min)
- Running (1 min)
- **Waiting** ‚Üê ‚úÖ Cluster pr√™t quand ce statut appara√Æt

üí° **PENDANT L'ATTENTE :** Vous pouvez rafra√Æchir la page toutes les 2 minutes pour voir l'√©volution

**‚úÖ QUAND STATUS = "WAITING" :** Cluster pr√™t ! Passez √† l'√©tape suivante

---

### √âtape 2.2 : Noter le DNS Master et Configurer Security Group

**üìç CE QUE VOUS ALLEZ FAIRE :** R√©cup√©rer l'adresse du cluster et ouvrir le port pour JupyterHub

#### Partie A : R√©cup√©rer le DNS Master

1. **Vous √™tes sur la page du cluster** (status "Waiting")

2. **Dans l'onglet "Summary" :**
   - Chercher la ligne : **"Master public DNS"**
   - Vous voyez quelque chose comme : `ec2-34-245-XXX-XXX.eu-west-1.compute.amazonaws.com`

3. **COPIER cette adresse** (s√©lectionner et Cmd+C)

4. **SAUVEGARDER cette adresse** dans un fichier texte (vous en aurez besoin plus tard)

#### Partie B : Configurer Security Group (Ouvrir port JupyterHub)

5. **Sur la m√™me page, chercher l'onglet "Security and access"**
   - Cliquer sur cet onglet

6. **Vous voyez une section "Security groups" avec :**
   - Security group for Primary (Master) : sg-XXXXXXXXX

7. **Cliquer sur le lien du Security group du Master** (sg-XXXXXXXXX en bleu)

   **Une nouvelle page s'ouvre** : EC2 Security Groups

8. **En bas de la page, onglet "Inbound rules" :**
   - Cliquer sur l'onglet **"Inbound rules"**

9. **Cliquer sur "Edit inbound rules"** (bouton √† droite)

10. **Page "Edit inbound rules" :**

    - **Cliquer sur "Add rule"** (bouton en bas √† gauche)

    **Nouvelle r√®gle appara√Æt :**
    - **Type :** S√©lectionner **"Custom TCP"**
    - **Port range :** Taper `9443`
    - **Source :** S√©lectionner **"My IP"** (AWS d√©tecte automatiquement votre IP)
    - **Description :** Taper `JupyterHub access`

    - **Cliquer sur "Save rules"** (bouton orange en bas √† droite)

**‚úÖ VOUS DEVEZ VOIR :**
- Message vert : "Security group rules modified successfully"
- Nouvelle r√®gle dans la liste : TCP 9443 avec votre IP

11. **Fermer cet onglet** et **retourner sur la page EMR**

**üìå PHASE 2 TERMIN√âE !**
- ‚úÖ Cluster EMR cr√©√© (Spot + Graviton2)
- ‚úÖ Status : Waiting (pr√™t √† utiliser)
- ‚úÖ DNS Master r√©cup√©r√©
- ‚úÖ Port 9443 ouvert pour JupyterHub

**‚è∏Ô∏è PAUSE POSSIBLE :** Cluster actif, vous pouvez faire une pause de 30 min max

---

## PHASE 3 : Connexion JupyterHub (15 minutes)

**‚è±Ô∏è Temps actif : 15 min | Temps attente : 0**

### √âtape 3.1 : Se Connecter √† JupyterHub EMR

**üìç CE QUE VOUS ALLEZ FAIRE :** Ouvrir JupyterHub qui tourne sur le cluster EMR

1. **Ouvrir un NOUVEL onglet** dans votre navigateur

2. **Dans la barre d'adresse, taper :**

   ```
   https://[VOTRE-DNS-MASTER]:9443
   ```

   **‚ö†Ô∏è Remplacer `[VOTRE-DNS-MASTER]` par le DNS que vous avez copi√©**

   **Exemple :**
   ```
   https://ec2-34-245-123-456.eu-west-1.compute.amazonaws.com:9443
   ```

   **Appuyer sur ENTR√âE**

3. **‚ö†Ô∏è AVERTISSEMENT S√âCURIT√â :**

   **Vous voyez : "Your connection is not private" ou "Connexion non s√©curis√©e"**

   **C'est NORMAL** (certificat auto-sign√© par AWS)

   **CHROME :**
   - Cliquer sur **"Advanced"** (ou "Param√®tres avanc√©s")
   - Cliquer sur **"Proceed to XXX (unsafe)"**

   **FIREFOX :**
   - Cliquer sur **"Advanced"**
   - Cliquer sur **"Accept the Risk and Continue"**

4. **Page de LOGIN JupyterHub :**

   **‚úÖ VOUS DEVEZ VOIR :**
   - Logo Jupyter
   - 2 champs : Username et Password
   - Bouton "Sign in"

   **Remplir :**
   - **Username :** Taper `jovyan` (nom par d√©faut EMR)
   - **Password :** Taper `jupyter` (mot de passe par d√©faut EMR)

   **Cliquer sur "Sign in"**

**‚úÖ VOUS DEVEZ VOIR :**
- Interface JupyterHub
- Liste de fichiers (peut √™tre vide)
- Boutons en haut : "Upload", "New", etc.

**F√âLICITATIONS !** Vous √™tes connect√© √† JupyterHub sur EMR ‚úÖ

---

### √âtape 3.2 : Tester l'Environnement

**üìç CE QUE VOUS ALLEZ FAIRE :** V√©rifier que Spark et TensorFlow fonctionnent

1. **Cliquer sur "New"** (en haut √† droite)
2. **S√©lectionner :** **"Python 3"** ou **"PySpark"**

**Un nouveau notebook s'ouvre**

3. **Dans la premi√®re cellule, taper :**

   ```python
   import pyspark
   print(f"PySpark version: {pyspark.__version__}")

   import tensorflow as tf
   print(f"TensorFlow version: {tf.__version__}")

   from pyspark.sql import SparkSession
   spark = SparkSession.builder.appName("P9-Test").getOrCreate()
   print("Spark session cr√©√©e ‚úÖ")
   ```

4. **Ex√©cuter la cellule :**
   - Appuyer sur **Shift + Entr√©e**

‚è±Ô∏è Attendre 10-30 secondes

**‚úÖ VOUS DEVEZ VOIR :**
```
PySpark version: 3.4.x
TensorFlow version: 2.5.x
Spark session cr√©√©e ‚úÖ
```

**Si vous voyez des erreurs :** V√©rifier que le cluster est bien en status "Waiting"

5. **Tester acc√®s S3 :**

   **‚ö†Ô∏è Remplacer "maxime" par VOTRE pr√©nom dans la commande ci-dessous :**

   ```python
   # Tester lecture S3
   df = spark.read.format("image").load("s3://fruits-classification-p9-maxime/Test/Apple*/")
   print(f"Images charg√©es: {df.count()}")
   ```

   **Ex√©cuter : Shift + Entr√©e**

‚è±Ô∏è Attendre 30-60 secondes

**‚úÖ VOUS DEVEZ VOIR :**
```
Images charg√©es: XXXX (nombre d'images Apple)
```

**PARFAIT !** Tout fonctionne ‚úÖ

6. **Fermer ce notebook de test** (ne pas sauvegarder)

**üìå PHASE 3 TERMIN√âE !**
- ‚úÖ JupyterHub accessible
- ‚úÖ PySpark fonctionne
- ‚úÖ TensorFlow fonctionne
- ‚úÖ Acc√®s S3 fonctionne

---

## PHASE 4 : Ex√©cution du Notebook PySpark (2 heures)

**‚è±Ô∏è Temps actif : 15 min | Temps attente : 1h45 (calculs)**

### √âtape 4.1 : Uploader le Notebook sur JupyterHub

**üìç CE QUE VOUS ALLEZ FAIRE :** Uploader votre notebook PySpark modifi√©

1. **Dans JupyterHub, cliquer sur "Upload"** (bouton en haut √† droite)

2. **Dans la fen√™tre qui s'ouvre :**
   - Naviguer vers : `/Users/maximenejad/Developer/OPC/P9/notebook/`
   - S√©lectionner : `P8_Notebook_Linux_EMR_PySpark_V1.0.ipynb`
   - **Cliquer sur "Open"** (ou "Ouvrir")

3. **Le fichier appara√Æt dans la liste avec un bouton bleu "Upload"**
   - **Cliquer sur le bouton bleu "Upload"**

‚è±Ô∏è Attendre 5-10 secondes

**‚úÖ VOUS DEVEZ VOIR :**
- Notebook appara√Æt dans la liste : `P8_Notebook_Linux_EMR_PySpark_V1.0.ipynb`

4. **Cliquer sur le nom du notebook** pour l'ouvrir

**‚úÖ VOUS DEVEZ VOIR :**
- Notebook s'ouvre
- Plein de cellules de code et markdown
- Titre : "D√©ployez un mod√®le dans le cloud"

---

### √âtape 4.2 : Configurer les Chemins S3 dans le Notebook

**üìç CE QUE VOUS ALLEZ FAIRE :** Modifier les chemins pour pointer vers votre bucket S3

1. **Chercher la section cloud (vers cellule 60+) :**
   - D√©filer vers le bas
   - Chercher : **"4.10.4 D√©finition des PATH"**

2. **Dans cette section, vous voyez du code comme :**

   ```python
   PATH = 's3://p8-data'
   PATH_Data = PATH+'/Test'
   PATH_Result = PATH+'/Results'
   ```

3. **REMPLACER uniquement la ligne PATH par :**

   **‚ö†Ô∏è Remplacer "maxime" par VOTRE pr√©nom :**

   ```python
   PATH = 's3://fruits-classification-p9-maxime'
   PATH_Data = PATH+'/Test'
   PATH_Result = PATH+'/Results'

   print('PATH:        '+\
         PATH+'\nPATH_Data:   '+\
         PATH_Data+'\nPATH_Result: '+PATH_Result)
   ```

4. **Sauvegarder le notebook :**
   - Menu : File ‚Üí Save
   - Ou : Cmd+S (Mac)

---

### √âtape 4.3 : Ex√©cuter le Pipeline Complet

**üìç CE QUE VOUS ALLEZ FAIRE :** Lancer tous les calculs (35-60 min)

**‚ö†Ô∏è IMPORTANT :** Ex√©cuter les cellules de la SECTION CLOUD uniquement (√† partir de la cellule ~57)

#### Ordre d'ex√©cution :

1. **Cellule INSTALLATION PACKAGES (Section cloud - 4.10.2) :**
   - Chercher la cellule avec : `!pip install Pandas pillow tensorflow pyspark pyarrow`
   - **Cliquer sur la cellule**
   - **Shift + Entr√©e** pour ex√©cuter
   - ‚è±Ô∏è **Attendre 2-3 minutes** (installation TensorFlow)
   - **‚úÖ V√©rifier :** Message "Successfully installed tensorflow-2.5.0..."

1bis. **Cellule IMPORTS (Section cloud - 4.10.3) :**
   - Chercher la cellule avec tous les imports (gzip, pickle, PySpark ML, etc.)
   - **Cliquer sur la cellule**
   - **Shift + Entr√©e** pour ex√©cuter
   - **‚úÖ V√©rifier :** Aucune erreur d'import

2. **Cellule SPARK SESSION :**
   - Normalement d√©j√† cr√©√©e par EMR
   - Si vous voyez `spark = SparkSession.builder...` ‚Üí Ex√©cuter
   - **‚úÖ V√©rifier :** Message "Spark session created"

3. **Cellule CHARGEMENT DATASET :**
   - `df = spark.read.format("image").load(PATH_Data)`
   - **Ex√©cuter**
   - ‚è±Ô∏è Attendre 2-5 minutes
   - **‚úÖ V√©rifier :** `df.count()` affiche nombre d'images

4. **Cellule PREPROCESSING :**
   - Normalisation des images
   - **Ex√©cuter**
   - ‚è±Ô∏è Attendre 1-2 minutes

5. **Cellule BROADCAST TENSORFLOW :**
   - Compression + diffusion des poids
   - **Ex√©cuter**
   - **‚úÖ V√©rifier :** Messages "Compression: XXX ‚Üí YYY bytes" et "Broadcast cr√©√© ‚úÖ"

6. **Cellule FEATURE EXTRACTION :**
   - `df_features = df.withColumn('features', predict_batch_udf(col('image')))`
   - **Ex√©cuter**
   - ‚è±Ô∏è **ATTENDRE 30-40 MINUTES** (le plus long)
   - **‚úÖ V√©rifier :** Barre de progression Spark (appara√Æt en bas)

**üí° PENDANT L'ATTENTE :** Vous pouvez faire autre chose, laisser l'onglet ouvert

7. **Cellule PCA PYSPARK :**
   - R√©duction de dimension 1280 ‚Üí 256
   - **Ex√©cuter**
   - ‚è±Ô∏è Attendre 5-10 minutes
   - **‚úÖ V√©rifier :** Message "Variance expliqu√©e: XX%" (doit √™tre ‚â• 90%)

8. **Cellule SAUVEGARDE S3 :**
   - `save_pca_results(df_pca, pca_output_path)`
   - **Ex√©cuter**
   - ‚è±Ô∏è Attendre 5 minutes
   - **‚úÖ V√©rifier :** Message "‚úÖ Sauvegarde termin√©e"

**‚è±Ô∏è DUR√âE TOTALE : 35-60 minutes**

---

### √âtape 4.4 : Capturer des Screenshots (Pour Pr√©sentation)

**üìç CE QUE VOUS ALLEZ FAIRE :** Prendre des photos d'√©cran pour votre soutenance

**PENDANT l'ex√©cution du notebook, capturer :**

1. **Screenshot AWS EMR Console :**
   - Retourner sur la page EMR dans AWS Console
   - Cluster status "Waiting" ou "Running"
   - **Cmd + Shift + 4** (Mac) ‚Üí Capturer la page
   - Sauvegarder dans `~/Desktop/`

2. **Screenshot JupyterHub :**
   - Page JupyterHub avec notebook en ex√©cution
   - Montrer les cellules et les outputs
   - **Cmd + Shift + 4**

3. **Screenshot Cellule PCA :**
   - Quand la cellule PCA affiche "Variance expliqu√©e: XX%"
   - **Cmd + Shift + 4**

4. **Screenshot S3 Bucket :**
   - AWS Console ‚Üí S3 ‚Üí Votre bucket ‚Üí Results/pca_output/
   - Montrer les fichiers .parquet cr√©√©s
   - **Cmd + Shift + 4**

**Sauvegarder tous les screenshots** dans un dossier pour la pr√©sentation

**üìå PHASE 4 TERMIN√âE !**
- ‚úÖ Notebook upload√© sur JupyterHub
- ‚úÖ Chemins S3 configur√©s
- ‚úÖ Pipeline ex√©cut√© avec succ√®s
- ‚úÖ PCA : Variance ‚â• 90% valid√©e
- ‚úÖ R√©sultats sauvegard√©s sur S3
- ‚úÖ Screenshots captur√©s

---

## PHASE 5 : Validation et Terminaison (30 minutes)

**‚è±Ô∏è Temps actif : 30 min | Temps attente : 0**

### √âtape 5.1 : V√©rifier les R√©sultats sur S3

**üìç CE QUE VOUS ALLEZ FAIRE :** V√©rifier que les fichiers PCA sont bien sur S3

1. **Ouvrir Terminal sur votre Mac**

2. **Lister les r√©sultats PCA sur S3 :**

   **‚ö†Ô∏è Remplacer "maxime" par VOTRE pr√©nom :**

   ```bash
   aws s3 ls s3://fruits-classification-p9-maxime/Results/pca_output/ --recursive
   ```

**‚úÖ VOUS DEVEZ VOIR :**
- Plein de fichiers `.parquet` :
  ```
  part-00000-XXX.parquet
  part-00001-XXX.parquet
  ...
  _SUCCESS
  ```

3. **T√©l√©charger un fichier pour validation :**

   ```bash
   aws s3 cp s3://fruits-classification-p9-maxime/Results/pca_output/part-00000-XXX.parquet \
     ~/Desktop/sample_pca.parquet
   ```

   **Remplacer `part-00000-XXX.parquet` par le vrai nom de fichier de la liste**

4. **V√©rifier le fichier avec Python :**

   ```bash
   python3 << 'EOF'
   import pandas as pd
   df = pd.read_parquet('~/Desktop/sample_pca.parquet')
   print(f"Colonnes: {df.columns.tolist()}")
   print(f"Nombre de lignes: {len(df)}")
   print(df.head())
   EOF
   ```

**‚úÖ VOUS DEVEZ VOIR :**
- Colonnes : ['path', 'label', 'features_pca']
- Nombre de lignes : XXX
- Tableau avec les donn√©es

**PARFAIT !** R√©sultats PCA valid√©s ‚úÖ

---

### √âtape 5.2 : V√©rifier les Co√ªts AWS

**üìç CE QUE VOUS ALLEZ FAIRE :** V√©rifier que vous n'avez pas d√©pass√© 10‚Ç¨

1. **AWS Console, barre de recherche :** Taper `Cost Explorer`
2. **Cliquer sur "Cost Explorer"**

3. **Page Cost Explorer :**
   - **Date range :** S√©lectionner "Last 7 days"
   - **Group by :** S√©lectionner "Service"
   - **Filter :** Ajouter filtre : Service = EMR, S3

**‚úÖ VOUS DEVEZ VOIR :**
- Graphique avec co√ªts par service
- Total : **< 10‚Ç¨** (normalement ~1.69‚Ç¨)

**D√©tails attendus :**
- EMR : ~1.11‚Ç¨ (3 heures)
- S3 : ~0.58‚Ç¨ (stockage + transferts)
- **Total : ~1.69‚Ç¨**

**‚úÖ Si < 10‚Ç¨ :** Tout est OK !
**‚ö†Ô∏è Si > 10‚Ç¨ :** V√©rifier qu'il n'y a pas d'autres services actifs

---

### √âtape 5.3 : ‚ö†Ô∏è TERMINER LE CLUSTER EMR (CRITIQUE !)

**üìç CE QUE VOUS ALLEZ FAIRE :** √âteindre le cluster pour arr√™ter les co√ªts

**‚ö†Ô∏è NE PAS OUBLIER CETTE √âTAPE ! SINON CO√õTS CONTINUENT !**

1. **AWS Console ‚Üí EMR ‚Üí Clusters**

2. **Vous voyez votre cluster dans la liste**

3. **COCHER la case** √† gauche du nom du cluster

4. **Cliquer sur le bouton "Terminate"** (bouton en haut)

5. **Popup de confirmation :**
   - **Lire le message** : "Are you sure you want to terminate..."
   - **Cliquer sur "Terminate"**

**‚úÖ VOUS DEVEZ VOIR :**
- Status du cluster change : "Waiting" ‚Üí "Terminating"

‚è±Ô∏è **ATTENDRE 5-10 minutes**

6. **Rafra√Æchir la page** (bouton refresh) toutes les 2 minutes

**‚úÖ QUAND STATUS = "TERMINATED" :**
- Cluster √©teint ‚úÖ
- Co√ªts arr√™t√©s ‚úÖ

**V√âRIFICATION FINALE :**

7. **V√©rifier qu'AUCUN autre cluster n'est actif :**
   - Dans la liste, filtrer par status : "Waiting" ou "Running"
   - **Liste doit √™tre VIDE**

**‚úÖ SI LISTE VIDE :** Plus aucun cluster actif, co√ªts EMR arr√™t√©s ‚úÖ

---

### √âtape 5.4 : Checklist Finale

**üìã V√©rifier que tout est OK avant de finir :**

- [ ] R√©sultats PCA pr√©sents sur S3 (fichiers .parquet)
- [ ] Variance PCA ‚â• 90% valid√©e
- [ ] Co√ªts AWS totaux < 10‚Ç¨ (normalement ~1.69‚Ç¨)
- [ ] Cluster EMR status = "Terminated"
- [ ] Aucun autre cluster actif
- [ ] Screenshots captur√©s (EMR, JupyterHub, PCA, S3)
- [ ] Fichier .pem sauvegard√© dans ~/.ssh/ (pour acc√®s futur si besoin)

**‚úÖ SI TOUT EST COCH√â :** PHASE 5 TERMIN√âE ! Projet AWS r√©ussi ! üéâ

---

**üìå TOUTES LES PHASES TERMIN√âES !**

**‚úÖ CE QUE VOUS AVEZ ACCOMPLI :**
1. Configuration AWS compl√®te (Budget, IAM, r√©gion eu-west-1)
2. Bucket S3 cr√©√© avec dataset upload√© (67k images)
3. Cluster EMR cr√©√© et configur√© (Spot + Graviton2)
4. JupyterHub accessible et fonctionnel
5. Notebook PySpark ex√©cut√© avec succ√®s
6. Broadcast TensorFlow optimis√© ‚úÖ
7. PCA PySpark (1280 ‚Üí 256 dimensions, variance ‚â• 90%) ‚úÖ
8. R√©sultats sauvegard√©s sur S3 ‚úÖ
9. Co√ªts ma√Ætris√©s (~1.69‚Ç¨ au lieu de 10‚Ç¨) ‚úÖ
10. Cluster termin√© (co√ªts arr√™t√©s) ‚úÖ

**üéì PROCHAINE √âTAPE :**
- Cr√©er le support de pr√©sentation (Feature 5)
- Utiliser les screenshots captur√©s
- Pr√©parer la soutenance de 20 minutes

---

## üÜò Troubleshooting (R√©solution de Probl√®mes)

### Probl√®me 1 : Cluster ne d√©marre pas

**SYMPT√îME :** Status reste bloqu√© sur "Starting" ou erreur "Insufficient capacity"

**CAUSE :** Capacit√© Spot insuffisante dans eu-west-1

**SOLUTION :**
1. Terminer le cluster actuel
2. Recr√©er cluster avec **"On-Demand"** au lieu de "Spot"
3. ‚ö†Ô∏è Co√ªts plus √©lev√©s (~3-4‚Ç¨ au lieu de 1.69‚Ç¨) mais √ßa fonctionnera

**ALTERNATIVE :**
- Utiliser instances **m5.xlarge** au lieu de m6g.xlarge (x86 au lieu de ARM)

---

### Probl√®me 2 : JupyterHub inaccessible

**SYMPT√îME :** Page ne charge pas, timeout, ou "Connection refused"

**CAUSES POSSIBLES :**

**Cause A : Security group mal configur√©**

**SOLUTION :**
1. AWS Console ‚Üí EMR ‚Üí Votre cluster ‚Üí "Security and access"
2. Cliquer sur Security group du Master
3. V√©rifier r√®gle inbound : Port 9443, Source = My IP
4. Si absente : Ajouter la r√®gle (voir Phase 2, √âtape 2.2)
5. **Important :** V√©rifier que c'est bien VOTRE IP publique
   - Aller sur https://whatismyipaddress.com pour voir votre IP
   - Comparer avec l'IP dans la r√®gle

**Cause B : Cluster pas encore pr√™t**

**SOLUTION :**
- V√©rifier que status = "Waiting" (pas "Starting" ou "Bootstrapping")
- Attendre encore 5-10 minutes

**Cause C : Mauvaise URL**

**SOLUTION :**
- V√©rifier URL : `https://[DNS-MASTER]:9443` (pas http, et bien port 9443)
- V√©rifier DNS Master copi√© correctement

---

### Probl√®me 3 : Acc√®s S3 refus√© depuis EMR

**SYMPT√îME :** Erreur dans le notebook : "Access Denied" ou "Permission denied" en lisant S3

**CAUSE :** R√¥le IAM EMR_EC2_DefaultRole_P9 n'a pas les permissions S3

**SOLUTION :**
1. AWS Console ‚Üí IAM ‚Üí Roles
2. Chercher : `EMR_EC2_DefaultRole_P9`
3. Cliquer dessus
4. Onglet "Permissions"
5. V√©rifier que la policy **AmazonS3FullAccess** est attach√©e
6. Si absente :
   - Cliquer "Attach policies"
   - Chercher `AmazonS3FullAccess`
   - Cocher et "Attach"
7. **Red√©marrer le cluster** (Terminate puis Create √† nouveau)

---

### Probl√®me 4 : D√©passement de co√ªts

**SYMPT√îME :** Email AWS disant que vous avez d√©pens√© > 10‚Ç¨

**CAUSES POSSIBLES :**
- Cluster EMR non termin√©
- Instances On-Demand au lieu de Spot
- Cluster tournant depuis plusieurs jours

**SOLUTION IMM√âDIATE :**
1. **AWS Console ‚Üí EMR ‚Üí Clusters**
2. **V√©rifier TOUS les clusters** (pas seulement le premier)
3. **TERMINER IMM√âDIATEMENT** tous les clusters actifs (status ‚â† Terminated)
4. **V√©rifier autres services :**
   - EC2 ‚Üí Instances (v√©rifier qu'aucune instance ne tourne)
   - RDS ‚Üí Databases (v√©rifier qu'aucune DB active)
5. **Cost Explorer :** Identifier quel service co√ªte cher

**PR√âVENTION :**
- Toujours configurer auto-termination (3 heures)
- V√©rifier status cluster apr√®s chaque session
- Activer alertes budget (Phase 0, √âtape 0.3)

---

### Probl√®me 5 : Dataset upload tr√®s lent

**SYMPT√îME :** AWS CLI upload prend > 3 heures

**CAUSES POSSIBLES :**
- Connexion internet lente
- Upload via Console (plus lent que CLI)

**SOLUTION :**
1. **V√©rifier votre connexion internet :**
   ```bash
   speedtest-cli
   ```
   - Upload speed doit √™tre > 5 Mbps

2. **Utiliser AWS CLI (plus rapide que Console)**

3. **Upload en plusieurs fois :**
   ```bash
   # Uploader seulement quelques classes pour tester :
   aws s3 sync ./data/raw/fruits-360_dataset/fruits-360/Training/Apple* \
     s3://fruits-classification-p9-maxime/Test/ \
     --region eu-west-1
   ```

4. **Lancer upload le soir et laisser tourner la nuit**

---

### Probl√®me 6 : Variance PCA < 90%

**SYMPT√îME :** Cellule PCA affiche "Variance expliqu√©e: 85%" (< 90%)

**CAUSE :** 256 composantes ne suffisent pas

**SOLUTION :**
1. **Dans le notebook, modifier la cellule PCA :**
   ```python
   # Au lieu de n_components=256, utiliser :
   df_pca, pca_model = apply_pca_reduction(df_prepared, n_components=512)
   ```

2. **R√©-ex√©cuter la cellule PCA**

3. **V√©rifier nouvelle variance** (doit √™tre ‚â• 90% avec 512 composantes)

**ALTERNATIVE :**
- Utiliser `n_components=384` (compromis entre 256 et 512)

---

### Probl√®me 7 : Import TensorFlow √©choue

**SYMPT√îME :** Erreur "ModuleNotFoundError: No module named 'tensorflow'"

**CAUSE :** Cellule d'installation des packages (4.10.2) n'a pas √©t√© ex√©cut√©e

**SOLUTION :**
1. **Retourner au d√©but de la section cloud du notebook**
2. **Chercher la cellule 4.10.2 :** `!pip install Pandas pillow tensorflow pyspark pyarrow`
3. **Ex√©cuter cette cellule** (attendre 2-3 minutes)
4. **Restart kernel si n√©cessaire** : Menu Kernel ‚Üí Restart
5. **R√©-ex√©cuter les cellules depuis le d√©but de la section cloud**

---

## üìö Ressources Compl√©mentaires

### Documentation AWS Officielle

- [AWS EMR Getting Started](https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-gs.html)
- [Amazon S3 User Guide](https://docs.aws.amazon.com/s3/index.html)
- [AWS EMR Pricing Calculator](https://aws.amazon.com/emr/pricing/)
- [AWS Cost Explorer](https://aws.amazon.com/aws-cost-management/aws-cost-explorer/)

### Commandes AWS CLI Utiles

```bash
# Lister tous les clusters EMR
aws emr list-clusters --region eu-west-1

# D√©crire un cluster sp√©cifique
aws emr describe-cluster --cluster-id j-XXXXXXXXXXXXX --region eu-west-1

# Terminer un cluster via CLI
aws emr terminate-clusters --cluster-ids j-XXXXXXXXXXXXX --region eu-west-1

# V√©rifier les co√ªts du mois en cours
aws ce get-cost-and-usage \
  --time-period Start=2025-10-01,End=2025-10-31 \
  --granularity MONTHLY \
  --metrics BlendedCost \
  --region eu-west-1

# Lister tous les buckets S3
aws s3 ls

# Lister contenu d'un bucket
aws s3 ls s3://fruits-classification-p9-maxime/ --recursive

# T√©l√©charger un dossier complet depuis S3
aws s3 sync s3://fruits-classification-p9-maxime/Results/ ./local_results/

# Supprimer un bucket S3 (ATTENTION : supprime tout)
aws s3 rb s3://fruits-classification-p9-maxime --force
```

### Nettoyage Apr√®s Soutenance (Optionnel)

**Si vous voulez supprimer TOUT pour √©conomiser (apr√®s soutenance) :**

```bash
# 1. Terminer tous les clusters EMR
aws emr list-clusters --region eu-west-1 --active
aws emr terminate-clusters --cluster-ids j-XXX j-YYY --region eu-west-1

# 2. Supprimer le dataset (garder Results/)
aws s3 rm s3://fruits-classification-p9-maxime/Test/ --recursive

# 3. OU supprimer tout le bucket
aws s3 rb s3://fruits-classification-p9-maxime --force

# 4. Supprimer les r√¥les IAM (optionnel)
# AWS Console ‚Üí IAM ‚Üí Roles ‚Üí S√©lectionner ‚Üí Delete
```

‚ö†Ô∏è **Attention :** Une fois supprim√©es, les donn√©es ne peuvent pas √™tre r√©cup√©r√©es !

---

**Version :** 2.0 - Guide Ultra-D√©taill√©
**Derni√®re mise √† jour :** 6 octobre 2025
**Auteur :** Assistant Claude pour Projet P9 Fruits Classification
**Public :** D√©butant AWS (aucune exp√©rience pr√©alable requise)

---

**üéâ F√âLICITATIONS !**

Si vous avez suivi ce guide jusqu'au bout, vous avez :
- ‚úÖ Ma√Ætris√© les bases d'AWS (S3, EMR, IAM)
- ‚úÖ D√©ploy√© une architecture Big Data cloud
- ‚úÖ Ex√©cut√© un pipeline PySpark distribu√©
- ‚úÖ Optimis√© les co√ªts (Spot, Graviton2)
- ‚úÖ Respect√© le RGPD (eu-west-1)
- ‚úÖ Valid√© les crit√®res d'√©valuation du projet

**Vous √™tes pr√™t pour la soutenance ! üöÄ**
