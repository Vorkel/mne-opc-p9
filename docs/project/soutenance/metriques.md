# MÃ©triques du Projet P9 - Fruits Classification

**Date de crÃ©ation** : 6 janvier 2025
**DerniÃ¨re mise Ã  jour** : ğŸ”´ **Ã€ COMPLÃ‰TER APRÃˆS EXÃ‰CUTION AWS**

---

## ğŸ“Š MÃ©triques du Dataset

### CaractÃ©ristiques gÃ©nÃ©rales

| MÃ©trique | Valeur | Source |
|----------|--------|--------|
| **Nombre total d'images** | 87 000+ | Dataset Fruits-360 |
| **Nombre de catÃ©gories** | 131 catÃ©gories de fruits | Dataset Fruits-360 |
| **Format des images** | 100x100 pixels, RGB (3 canaux) | Dataset Fruits-360 |
| **Volume total** | ~2 GB | Mesure locale |
| **Taille moyenne par image** | ~23 KB | Calcul : 2GB / 87 000 |

### Distribution (exemples de catÃ©gories)

| CatÃ©gorie | Nombre d'images approximatif |
|-----------|------------------------------|
| Pomme | ~6 500 |
| Banane | ~4 900 |
| Orange | ~3 200 |
| Fraise | ~2 100 |
| ... | ... |
| **Total** | **87 000+** |

---

## âš™ï¸ MÃ©triques du Pipeline PySpark

### Ã‰tape 1 : Chargement depuis S3

| MÃ©trique | Valeur | Statut |
|----------|--------|--------|
| **Images chargÃ©es** | ğŸ”´ **[Ã€ MESURER APRÃˆS AWS]** | â³ En attente |
| **Images invalides ignorÃ©es** | ğŸ”´ **[Ã€ MESURER APRÃˆS AWS]** | â³ En attente |
| **Temps de chargement** | ğŸ”´ **[Ã€ MESURER APRÃˆS AWS]** minutes | â³ En attente |
| **Taille totale chargÃ©e** | ğŸ”´ **[Ã€ MESURER APRÃˆS AWS]** GB | â³ En attente |

**Comment mesurer :**
```python
# Dans le notebook Jupyter sur EMR, aprÃ¨s chargement
import time
start_time = time.time()
df_images = spark.read.format("image").option("dropInvalid", True).load("s3://bucket/Test/")
load_time = time.time() - start_time
print(f"Images chargÃ©es : {df_images.count()}")
print(f"Temps de chargement : {load_time:.2f} secondes")
```

---

### Ã‰tape 2 : Preprocessing

| MÃ©trique | Valeur | Statut |
|----------|--------|--------|
| **Images preprocessÃ©es** | ğŸ”´ **[Ã€ MESURER APRÃˆS AWS]** | â³ En attente |
| **Temps de preprocessing** | ğŸ”´ **[Ã€ MESURER APRÃˆS AWS]** minutes | â³ En attente |
| **Ã‰checs preprocessing** | ğŸ”´ **[Ã€ MESURER APRÃˆS AWS]** | â³ En attente |

**Comment mesurer :**
```python
# AprÃ¨s preprocessing
start_time = time.time()
df_preprocessed = df_images.withColumn("image_normalized", preprocess_udf("image"))
df_preprocessed.cache()  # Force l'exÃ©cution
count = df_preprocessed.count()
preprocess_time = time.time() - start_time
print(f"Images preprocessÃ©es : {count}")
print(f"Temps de preprocessing : {preprocess_time:.2f} secondes")
```

---

### Ã‰tape 3 : Feature Extraction (MobileNetV2)

| MÃ©trique | Valeur | Statut |
|----------|--------|--------|
| **Images traitÃ©es** | ğŸ”´ **[Ã€ MESURER APRÃˆS AWS]** | â³ En attente |
| **Features extraites par image** | 1280 (MobileNetV2 output) | âœ… Connu |
| **Temps d'extraction** | ğŸ”´ **[Ã€ MESURER APRÃˆS AWS]** minutes | â³ En attente |
| **Taille modÃ¨le (avant compression)** | ~14 MB | âœ… MesurÃ© |
| **Taille modÃ¨le (aprÃ¨s compression gzip)** | ~5 MB | âœ… MesurÃ© |
| **Ratio compression** | ~65% | âœ… CalculÃ© |

**Comment mesurer :**
```python
# Taille modÃ¨le
import pickle, gzip
from tensorflow.keras.applications import MobileNetV2
model = MobileNetV2(weights='imagenet', include_top=False, pooling='avg')
model_bytes_uncompressed = pickle.dumps(model)
model_bytes_compressed = gzip.compress(model_bytes_uncompressed, compresslevel=9)
print(f"Taille avant compression : {len(model_bytes_uncompressed) / 1024**2:.2f} MB")
print(f"Taille aprÃ¨s compression : {len(model_bytes_compressed) / 1024**2:.2f} MB")
print(f"Ratio compression : {(1 - len(model_bytes_compressed)/len(model_bytes_uncompressed))*100:.1f}%")

# Temps d'extraction
start_time = time.time()
df_features = extract_features(df_preprocessed, model_broadcast)
df_features.cache()
count = df_features.count()
extraction_time = time.time() - start_time
print(f"Features extraites pour {count} images")
print(f"Temps d'extraction : {extraction_time:.2f} secondes")
```

---

### Ã‰tape 4 : RÃ©duction PCA

| MÃ©trique | Valeur | Statut |
|----------|--------|--------|
| **Dimensions initiales** | 1280 | âœ… Connu |
| **Dimensions finales (k)** | 256 | âœ… Connu |
| **RÃ©duction de dimensions** | 80% | âœ… CalculÃ© (1 - 256/1280) |
| **Variance expliquÃ©e** | ğŸ”´ **[Ã€ MESURER APRÃˆS AWS - ESTIMATION 90-95%]** | â³ En attente |
| **Temps de fit PCA** | ğŸ”´ **[Ã€ MESURER APRÃˆS AWS]** minutes | â³ En attente |
| **Temps de transform PCA** | ğŸ”´ **[Ã€ MESURER APRÃˆS AWS]** minutes | â³ En attente |

**Comment mesurer :**
```python
# Variance expliquÃ©e
from pyspark.ml.feature import PCA
pca = PCA(k=256, inputCol="features_vector", outputCol="features_pca")

# Fit
start_time = time.time()
pca_model = pca.fit(df_vectorized)
fit_time = time.time() - start_time
print(f"Temps de fit PCA : {fit_time:.2f} secondes")

# Variance expliquÃ©e
variance_expliquee = sum(pca_model.explainedVariance[:256])
print(f"Variance expliquÃ©e : {variance_expliquee:.2%}")

# Transform
start_time = time.time()
df_pca = pca_model.transform(df_vectorized)
df_pca.cache()
count = df_pca.count()
transform_time = time.time() - start_time
print(f"Temps de transform PCA : {transform_time:.2f} secondes")
print(f"Vecteurs PCA gÃ©nÃ©rÃ©s : {count}")
```

**Graphique variance cumulative :**
```python
# GÃ©nÃ©rer graphique variance
import matplotlib.pyplot as plt
variance = pca_model.explainedVariance
cumulative_variance = []
total = 0
for v in variance:
    total += v
    cumulative_variance.append(total)

plt.figure(figsize=(10, 6))
plt.plot(range(1, len(cumulative_variance)+1), cumulative_variance, linewidth=2)
plt.axhline(y=0.9, color='r', linestyle='--', label='90% seuil', linewidth=2)
plt.xlabel('Nombre de composantes principales', fontsize=12)
plt.ylabel('Variance expliquÃ©e cumulative', fontsize=12)
plt.title('Variance expliquÃ©e par PCA - Fruits Classification', fontsize=14, fontweight='bold')
plt.legend(fontsize=10)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig('variance_pca.png', dpi=300)
plt.show()
print(f"Variance Ã  256 composantes : {cumulative_variance[255]:.2%}")
```

---

### Ã‰tape 5 : Sauvegarde S3

| MÃ©trique | Valeur | Statut |
|----------|--------|--------|
| **Vecteurs sauvegardÃ©s** | ğŸ”´ **[Ã€ MESURER APRÃˆS AWS]** | â³ En attente |
| **Temps d'Ã©criture** | ğŸ”´ **[Ã€ MESURER APRÃˆS AWS]** minutes | â³ En attente |
| **Taille fichiers Parquet** | ğŸ”´ **[Ã€ MESURER APRÃˆS AWS]** MB | â³ En attente |
| **Nombre de partitions** | ğŸ”´ **[Ã€ MESURER APRÃˆS AWS]** | â³ En attente |

**Comment mesurer :**
```python
# Sauvegarde
start_time = time.time()
df_pca.select("path", "label", "features_pca") \
    .write \
    .mode("overwrite") \
    .parquet("s3://bucket/Results/pca_output/")
write_time = time.time() - start_time
print(f"Temps d'Ã©criture : {write_time:.2f} secondes")

# VÃ©rifier taille des fichiers (via AWS CLI ou Console S3)
# aws s3 ls s3://bucket/Results/pca_output/ --recursive --human-readable --summarize
```

---

### MÃ©triques globales du pipeline

| MÃ©trique | Valeur | Statut |
|----------|--------|--------|
| **Temps total d'exÃ©cution** | ğŸ”´ **[Ã€ MESURER APRÃˆS AWS]** minutes | â³ En attente |
| **DÃ©bit moyen** | ğŸ”´ **[Ã€ CALCULER]** images/minute | â³ En attente |
| **Taux d'Ã©chec** | ğŸ”´ **[Ã€ MESURER APRÃˆS AWS]** % | â³ En attente |

**Comment calculer :**
```python
# DÃ©bit moyen
nombre_images = 87000
temps_total_minutes = XXX  # Ã€ mesurer
debit = nombre_images / temps_total_minutes
print(f"DÃ©bit moyen : {debit:.1f} images/minute")

# Taux d'Ã©chec
images_chargees = XXX
images_finales = XXX
taux_echec = (1 - images_finales/images_chargees) * 100
print(f"Taux d'Ã©chec : {taux_echec:.2f}%")
```

---

## ğŸ–¥ï¸ MÃ©triques du Cluster EMR

### Configuration

| MÃ©trique | Valeur | Statut |
|----------|--------|--------|
| **Type de cluster** | AWS EMR | âœ… Connu |
| **Version EMR** | ğŸ”´ **[Ã€ NOTER APRÃˆS CRÃ‰ATION]** | â³ En attente |
| **Version Spark** | 3.4+ (prÃ©vu) | âœ… Connu |
| **RÃ©gion AWS** | eu-west-1 (Ireland) | âœ… Connu |

### NÅ“uds

| Type de nÅ“ud | Instance | vCPU | RAM | Stockage | Nombre |
|--------------|----------|------|-----|----------|--------|
| **Master** | m6g.xlarge | 4 | 16 GB | EBS 32 GB | 1 |
| **Core** | m6g.large | 2 | 8 GB | EBS 32 GB | 2 |
| **Total** | - | **8 vCPU** | **32 GB RAM** | **96 GB** | **3** |

### Utilisation des ressources

| MÃ©trique | Valeur | Statut |
|----------|--------|--------|
| **CPU moyen (master)** | ğŸ”´ **[Ã€ MESURER PENDANT EXÃ‰CUTION]** % | â³ En attente |
| **CPU moyen (workers)** | ğŸ”´ **[Ã€ MESURER PENDANT EXÃ‰CUTION]** % | â³ En attente |
| **RAM utilisÃ©e (master)** | ğŸ”´ **[Ã€ MESURER PENDANT EXÃ‰CUTION]** GB | â³ En attente |
| **RAM utilisÃ©e (workers)** | ğŸ”´ **[Ã€ MESURER PENDANT EXÃ‰CUTION]** GB | â³ En attente |
| **DurÃ©e de vie du cluster** | ğŸ”´ **[Ã€ MESURER APRÃˆS TERMINAISON]** heures | â³ En attente |

**Comment mesurer :**
- Via CloudWatch Metrics (CPU, RAM, Network)
- Via Spark UI (onglet Executors)
- Via Ganglia (EMR monitoring natif)

---

## ğŸ’° MÃ©triques de CoÃ»ts AWS

### Estimation thÃ©orique (avant exÃ©cution)

| Service | DÃ©tail | DurÃ©e | CoÃ»t unitaire (Spot) | CoÃ»t total |
|---------|--------|-------|----------------------|------------|
| **EMR Master** | m6g.xlarge Spot | 2h | ~0,04â‚¬/h | ~0,08â‚¬ |
| **EMR Core (x2)** | m6g.large Spot | 2h | ~0,02â‚¬/h Ã— 2 | ~0,08â‚¬ |
| **S3 Storage** | 2 GB stockÃ©s + rÃ©sultats (~500 MB) | 1 mois | ~0,023â‚¬/GB/mois | ~0,06â‚¬ |
| **S3 Transfert IN** | 2 GB upload | - | Gratuit | 0â‚¬ |
| **S3 Transfert OUT** | RÃ©sultats (~500 MB download) | - | Gratuit (mÃªme rÃ©gion) | 0â‚¬ |
| **EMR Service Fee** | 10% du coÃ»t instances | 2h | - | ~0,02â‚¬ |
| **TOTAL ESTIMÃ‰** | | | | **~0,24â‚¬** |

**Note :** Cette estimation est trÃ¨s conservatrice. Le coÃ»t rÃ©el pourrait Ãªtre lÃ©gÃ¨rement supÃ©rieur selon :
- Le temps d'exÃ©cution rÃ©el
- Les transferts de donnÃ©es
- Les logs CloudWatch
- La consommation S3 rÃ©elle

### CoÃ»ts rÃ©els (aprÃ¨s exÃ©cution)

| Service | DÃ©tail | DurÃ©e | CoÃ»t unitaire | CoÃ»t total |
|---------|--------|-------|---------------|------------|
| **EMR Master** | ğŸ”´ **[Ã€ RELEVER FACTURE AWS]** | ğŸ”´ **[X]** h | ğŸ”´ **[X]** â‚¬/h | ğŸ”´ **[X]** â‚¬ |
| **EMR Core (x2)** | ğŸ”´ **[Ã€ RELEVER FACTURE AWS]** | ğŸ”´ **[X]** h | ğŸ”´ **[X]** â‚¬/h | ğŸ”´ **[X]** â‚¬ |
| **S3 Storage** | ğŸ”´ **[Ã€ RELEVER FACTURE AWS]** | 1 mois | ğŸ”´ **[X]** â‚¬/GB | ğŸ”´ **[X]** â‚¬ |
| **S3 Requests** | ğŸ”´ **[Ã€ RELEVER FACTURE AWS]** | - | - | ğŸ”´ **[X]** â‚¬ |
| **S3 Transfert** | ğŸ”´ **[Ã€ RELEVER FACTURE AWS]** | - | - | ğŸ”´ **[X]** â‚¬ |
| **EMR Service Fee** | ğŸ”´ **[Ã€ RELEVER FACTURE AWS]** | - | - | ğŸ”´ **[X]** â‚¬ |
| **CloudWatch Logs** | ğŸ”´ **[Ã€ RELEVER FACTURE AWS]** | - | - | ğŸ”´ **[X]** â‚¬ |
| **Autres** | ğŸ”´ **[Ã€ RELEVER FACTURE AWS]** | - | - | ğŸ”´ **[X]** â‚¬ |
| **TOTAL RÃ‰EL** | | | | ğŸ”´ **[X,XX]** â‚¬ |

**Ã‰conomie vs budget :** ğŸ”´ **[Ã€ CALCULER]** % (Budget : 10â‚¬)

**Comment obtenir les coÃ»ts rÃ©els :**
1. Attendre 24-48h aprÃ¨s terminaison du cluster (facturation diffÃ©rÃ©e)
2. Aller sur AWS Console â†’ Billing â†’ Bills
3. SÃ©lectionner le mois en cours
4. Filtrer par service : EMR, S3
5. Exporter le dÃ©tail en CSV
6. Remplir le tableau ci-dessus

---

## ğŸ“ˆ MÃ©triques de Performance

### Comparaison thÃ©orique : Local vs EMR

| MÃ©trique | Local (1 machine) | EMR (1 master + 2 workers) | Gain |
|----------|-------------------|---------------------------|------|
| **vCPU disponibles** | 4-8 (laptop) | 8 (cluster) | ~1-2x |
| **RAM disponible** | 8-16 GB (laptop) | 32 GB (cluster) | ~2-4x |
| **Temps estimÃ©** | 6-8h | 1-2h | ~4-6x |
| **ScalabilitÃ©** | Non (RAM limitÃ©e) | Oui (ajout workers) | âˆ |

**Note :** Le gain rÃ©el dÃ©pend du partitionnement Spark et de l'overhead rÃ©seau.

---

## ğŸ”’ MÃ©triques de ConformitÃ© RGPD

| CritÃ¨re | Valeur | Validation |
|---------|--------|------------|
| **RÃ©gion stockage S3** | eu-west-1 (Ireland, UE) | âœ… Conforme |
| **RÃ©gion cluster EMR** | eu-west-1 (Ireland, UE) | âœ… Conforme |
| **Chiffrement S3 (repos)** | AES-256 | âœ… Conforme |
| **Chiffrement S3 (transit)** | HTTPS/TLS | âœ… Conforme |
| **Transferts hors UE** | 0 transfert | âœ… Conforme |
| **Permissions IAM** | Principe du moindre privilÃ¨ge | âœ… Conforme |
| **Audit trail** | CloudTrail activÃ© | âœ… Conforme |

**RÃ©sultat :** 7/7 critÃ¨res conformes â†’ **100% conforme RGPD**

---

## ğŸ¯ MÃ©triques de QualitÃ© des RÃ©sultats

### Features PCA

| MÃ©trique | Valeur | Statut |
|----------|--------|--------|
| **Dimensions rÃ©duites** | 256 | âœ… ValidÃ© |
| **Variance conservÃ©e** | ğŸ”´ **[Ã€ MESURER - ESTIMATION 90-95%]** % | â³ En attente |
| **Seuil minimum variance** | 90% | âœ… Objectif fixÃ© |
| **Variance au-dessus seuil ?** | ğŸ”´ **[OUI/NON Ã€ VALIDER]** | â³ En attente |

### Format de sortie

| MÃ©trique | Valeur | Statut |
|----------|--------|--------|
| **Format fichiers** | Parquet | âœ… ValidÃ© |
| **Compression** | Snappy (dÃ©faut Parquet) | âœ… ValidÃ© |
| **Colonnes sauvegardÃ©es** | path, label, features_pca | âœ… ValidÃ© |
| **Taille par vecteur** | ~1 KB (256 floats) | âœ… EstimÃ© |

---

## ğŸ“‹ Checklist de collecte des mÃ©triques APRÃˆS AWS

### Pendant l'exÃ©cution du notebook

- [ ] **Mesurer temps chargement S3** (cellule aprÃ¨s `spark.read.format("image")`)
- [ ] **Mesurer temps preprocessing** (cellule aprÃ¨s UDF preprocessing)
- [ ] **Mesurer taille modÃ¨le avant/aprÃ¨s compression** (cellule broadcast)
- [ ] **Mesurer temps extraction features** (cellule aprÃ¨s `extract_features()`)
- [ ] **Mesurer temps fit PCA** (cellule aprÃ¨s `pca.fit()`)
- [ ] **Mesurer variance expliquÃ©e PCA** (cellule aprÃ¨s `pca_model.explainedVariance`)
- [ ] **GÃ©nÃ©rer graphique variance PCA** (cellule matplotlib)
- [ ] **Mesurer temps transform PCA** (cellule aprÃ¨s `pca_model.transform()`)
- [ ] **Mesurer temps Ã©criture S3** (cellule aprÃ¨s `.write.parquet()`)
- [ ] **Mesurer temps total** (dÃ©but premiÃ¨re cellule â†’ fin derniÃ¨re cellule)

### AprÃ¨s terminaison du cluster

- [ ] **VÃ©rifier taille fichiers Parquet sur S3** (Console S3 ou AWS CLI)
- [ ] **Relever durÃ©e de vie du cluster** (Console EMR â†’ Cluster â†’ Timeline)
- [ ] **TÃ©lÃ©charger graphique variance PCA** depuis JupyterHub
- [ ] **Prendre screenshots** (Console EMR, JupyterHub, S3 bucket)

### 24-48h aprÃ¨s terminaison

- [ ] **Consulter facture AWS** (Billing â†’ Bills)
- [ ] **Exporter dÃ©tails coÃ»ts** (CSV ou Excel)
- [ ] **Remplir tableau coÃ»ts rÃ©els** dans ce fichier
- [ ] **Calculer Ã©conomie vs budget** (10â‚¬ - coÃ»t rÃ©el)

---

## ğŸ“Š Tableau de synthÃ¨se pour la prÃ©sentation

**Ce tableau sera utilisÃ© dans le slide 17 de la prÃ©sentation.**

| CatÃ©gorie | MÃ©trique | Valeur |
|-----------|----------|--------|
| **Dataset** | Volume traitÃ© | 87 000 images (~2 GB) |
| **Pipeline** | Temps total exÃ©cution | ğŸ”´ **[X minutes]** |
| **Pipeline** | Dimensions | 1280 â†’ 256 (rÃ©duction 80%) |
| **Pipeline** | Variance PCA | ğŸ”´ **[X%]** |
| **Cluster** | Configuration | 1 master + 2 workers (Graviton2) |
| **Cluster** | RÃ©gion | eu-west-1 (RGPD âœ…) |
| **CoÃ»ts** | Total AWS | ğŸ”´ **[X,XXâ‚¬]** |
| **CoÃ»ts** | Ã‰conomie vs budget | ğŸ”´ **[X%]** (budget 10â‚¬) |
| **ConformitÃ©** | RGPD | âœ… 100% conforme |
| **QualitÃ©** | Pipeline | âœ… Complet et fonctionnel |

---

**Date de finalisation prÃ©vue :** AprÃ¨s exÃ©cution Feature 4 (AWS Deployment)
**Responsable :** Maxime Nejad
