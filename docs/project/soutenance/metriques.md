# M√©triques du Projet P9 - Fruits Classification

**Date de cr√©ation** : 6 janvier 2025
**Derni√®re mise √† jour** : üî¥ **√Ä COMPL√âTER APR√àS EX√âCUTION AWS**

---

## üìä M√©triques du Dataset

### Caract√©ristiques g√©n√©rales

| M√©trique | Valeur | Source |
|----------|--------|--------|
| **Nombre total d'images** | 87 000+ | Dataset Fruits-360 |
| **Nombre de cat√©gories** | 131 cat√©gories de fruits | Dataset Fruits-360 |
| **Format des images** | 100x100 pixels, RGB (3 canaux) | Dataset Fruits-360 |
| **Volume total** | ~2 GB | Mesure locale |
| **Taille moyenne par image** | ~23 KB | Calcul : 2GB / 87 000 |

### Distribution (exemples de cat√©gories)

| Cat√©gorie | Nombre d'images approximatif |
|-----------|------------------------------|
| Pomme | ~6 500 |
| Banane | ~4 900 |
| Orange | ~3 200 |
| Fraise | ~2 100 |
| ... | ... |
| **Total** | **87 000+** |

---

## ‚öôÔ∏è M√©triques du Pipeline PySpark

### √âtape 1 : Chargement depuis S3

| M√©trique | Valeur | Statut |
|----------|--------|--------|
| **Images charg√©es** | üî¥ **[√Ä MESURER APR√àS AWS]** | ‚è≥ En attente |
| **Images invalides ignor√©es** | üî¥ **[√Ä MESURER APR√àS AWS]** | ‚è≥ En attente |
| **Temps de chargement** | üî¥ **[√Ä MESURER APR√àS AWS]** minutes | ‚è≥ En attente |
| **Taille totale charg√©e** | üî¥ **[√Ä MESURER APR√àS AWS]** GB | ‚è≥ En attente |

**Comment mesurer :**
```python
# Dans le notebook Jupyter sur EMR, apr√®s chargement
import time
start_time = time.time()
df_images = spark.read.format("image").option("dropInvalid", True).load("s3://bucket/Test/")
load_time = time.time() - start_time
print(f"Images charg√©es : {df_images.count()}")
print(f"Temps de chargement : {load_time:.2f} secondes")
```

---

### √âtape 2 : Preprocessing

| M√©trique | Valeur | Statut |
|----------|--------|--------|
| **Images preprocess√©es** | üî¥ **[√Ä MESURER APR√àS AWS]** | ‚è≥ En attente |
| **Temps de preprocessing** | üî¥ **[√Ä MESURER APR√àS AWS]** minutes | ‚è≥ En attente |
| **√âchecs preprocessing** | üî¥ **[√Ä MESURER APR√àS AWS]** | ‚è≥ En attente |

**Comment mesurer :**
```python
# Apr√®s preprocessing
start_time = time.time()
df_preprocessed = df_images.withColumn("image_normalized", preprocess_udf("image"))
df_preprocessed.cache()  # Force l'ex√©cution
count = df_preprocessed.count()
preprocess_time = time.time() - start_time
print(f"Images preprocess√©es : {count}")
print(f"Temps de preprocessing : {preprocess_time:.2f} secondes")
```

---

### √âtape 3 : Feature Extraction (MobileNetV2)

| M√©trique | Valeur | Statut |
|----------|--------|--------|
| **Images trait√©es** | üî¥ **[√Ä MESURER APR√àS AWS]** | ‚è≥ En attente |
| **Features extraites par image** | 1280 (MobileNetV2 output) | ‚úÖ Connu |
| **Temps d'extraction** | üî¥ **[√Ä MESURER APR√àS AWS]** minutes | ‚è≥ En attente |
| **Taille mod√®le (avant compression)** | ~14 MB | ‚úÖ Mesur√© |
| **Taille mod√®le (apr√®s compression gzip)** | ~5 MB | ‚úÖ Mesur√© |
| **Ratio compression** | ~65% | ‚úÖ Calcul√© |

**Comment mesurer :**
```python
# Taille mod√®le
import pickle, gzip
from tensorflow.keras.applications import MobileNetV2
model = MobileNetV2(weights='imagenet', include_top=False, pooling='avg')
model_bytes_uncompressed = pickle.dumps(model)
model_bytes_compressed = gzip.compress(model_bytes_uncompressed, compresslevel=9)
print(f"Taille avant compression : {len(model_bytes_uncompressed) / 1024**2:.2f} MB")
print(f"Taille apr√®s compression : {len(model_bytes_compressed) / 1024**2:.2f} MB")
print(f"Ratio compression : {(1 - len(model_bytes_compressed)/len(model_bytes_uncompressed))*100:.1f}%")

# Temps d'extraction
start_time = time.time()
df_features = extract_features(df_preprocessed, model_broadcast)
df_features.cache()
count = df_features.count()
extraction_time = time.time() - start_time
print(f"Features extraites pour {count} images")
print(f"Temps d'extraction : {extraction_time:.2f} secondes")
```

---

### √âtape 4 : R√©duction PCA

| M√©trique | Valeur | Statut |
|----------|--------|--------|
| **Dimensions initiales** | 1280 | ‚úÖ Connu |
| **Dimensions finales (k)** | 256 | ‚úÖ Connu |
| **R√©duction de dimensions** | 80% | ‚úÖ Calcul√© (1 - 256/1280) |
| **Variance expliqu√©e** | üî¥ **[√Ä MESURER APR√àS AWS - ESTIMATION 90-95%]** | ‚è≥ En attente |
| **Temps de fit PCA** | üî¥ **[√Ä MESURER APR√àS AWS]** minutes | ‚è≥ En attente |
| **Temps de transform PCA** | üî¥ **[√Ä MESURER APR√àS AWS]** minutes | ‚è≥ En attente |

**Comment mesurer :**
```python
# Variance expliqu√©e
from pyspark.ml.feature import PCA
pca = PCA(k=256, inputCol="features_vector", outputCol="features_pca")

# Fit
start_time = time.time()
pca_model = pca.fit(df_vectorized)
fit_time = time.time() - start_time
print(f"Temps de fit PCA : {fit_time:.2f} secondes")

# Variance expliqu√©e
variance_expliquee = sum(pca_model.explainedVariance[:256])
print(f"Variance expliqu√©e : {variance_expliquee:.2%}")

# Transform
start_time = time.time()
df_pca = pca_model.transform(df_vectorized)
df_pca.cache()
count = df_pca.count()
transform_time = time.time() - start_time
print(f"Temps de transform PCA : {transform_time:.2f} secondes")
print(f"Vecteurs PCA g√©n√©r√©s : {count}")
```

**Graphique variance cumulative :**
```python
# G√©n√©rer graphique variance
import matplotlib.pyplot as plt
variance = pca_model.explainedVariance
cumulative_variance = []
total = 0
for v in variance:
    total += v
    cumulative_variance.append(total)

plt.figure(figsize=(10, 6))
plt.plot(range(1, len(cumulative_variance)+1), cumulative_variance, linewidth=2)
plt.axhline(y=0.9, color='r', linestyle='--', label='90% seuil', linewidth=2)
plt.xlabel('Nombre de composantes principales', fontsize=12)
plt.ylabel('Variance expliqu√©e cumulative', fontsize=12)
plt.title('Variance expliqu√©e par PCA - Fruits Classification', fontsize=14, fontweight='bold')
plt.legend(fontsize=10)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig('variance_pca.png', dpi=300)
plt.show()
print(f"Variance √† 256 composantes : {cumulative_variance[255]:.2%}")
```

---

### √âtape 5 : Sauvegarde S3

| M√©trique | Valeur | Statut |
|----------|--------|--------|
| **Vecteurs sauvegard√©s** | üî¥ **[√Ä MESURER APR√àS AWS]** | ‚è≥ En attente |
| **Temps d'√©criture** | üî¥ **[√Ä MESURER APR√àS AWS]** minutes | ‚è≥ En attente |
| **Taille fichiers Parquet** | üî¥ **[√Ä MESURER APR√àS AWS]** MB | ‚è≥ En attente |
| **Nombre de partitions** | üî¥ **[√Ä MESURER APR√àS AWS]** | ‚è≥ En attente |

**Comment mesurer :**
```python
# Sauvegarde
start_time = time.time()
df_pca.select("path", "label", "features_pca") \
    .write \
    .mode("overwrite") \
    .parquet("s3://bucket/Results/pca_output/")
write_time = time.time() - start_time
print(f"Temps d'√©criture : {write_time:.2f} secondes")

# V√©rifier taille des fichiers (via AWS CLI ou Console S3)
# aws s3 ls s3://bucket/Results/pca_output/ --recursive --human-readable --summarize
```

---

### M√©triques globales du pipeline

| M√©trique | Valeur | Statut |
|----------|--------|--------|
| **Temps total d'ex√©cution** | üî¥ **[√Ä MESURER APR√àS AWS]** minutes | ‚è≥ En attente |
| **D√©bit moyen** | üî¥ **[√Ä CALCULER]** images/minute | ‚è≥ En attente |
| **Taux d'√©chec** | üî¥ **[√Ä MESURER APR√àS AWS]** % | ‚è≥ En attente |

**Comment calculer :**
```python
# D√©bit moyen
nombre_images = 87000
temps_total_minutes = XXX  # √Ä mesurer
debit = nombre_images / temps_total_minutes
print(f"D√©bit moyen : {debit:.1f} images/minute")

# Taux d'√©chec
images_chargees = XXX
images_finales = XXX
taux_echec = (1 - images_finales/images_chargees) * 100
print(f"Taux d'√©chec : {taux_echec:.2f}%")
```

---

## üñ•Ô∏è M√©triques du Cluster EMR

### Configuration

| M√©trique | Valeur | Statut |
|----------|--------|--------|
| **Type de cluster** | AWS EMR | ‚úÖ Connu |
| **Version EMR** | üî¥ **[√Ä NOTER APR√àS CR√âATION]** | ‚è≥ En attente |
| **Version Spark** | 3.4+ (pr√©vu) | ‚úÖ Connu |
| **R√©gion AWS** | eu-west-1 (Ireland) | ‚úÖ Connu |

### N≈ìuds

| Type de n≈ìud | Instance | vCPU | RAM | Stockage | Nombre |
|--------------|----------|------|-----|----------|--------|
| **Master** | m6g.xlarge | 4 | 16 GB | EBS 32 GB | 1 |
| **Core** | m6g.large | 2 | 8 GB | EBS 32 GB | 2 |
| **Total** | - | **8 vCPU** | **32 GB RAM** | **96 GB** | **3** |

### Utilisation des ressources

| M√©trique | Valeur | Statut |
|----------|--------|--------|
| **CPU moyen (master)** | üî¥ **[√Ä MESURER PENDANT EX√âCUTION]** % | ‚è≥ En attente |
| **CPU moyen (workers)** | üî¥ **[√Ä MESURER PENDANT EX√âCUTION]** % | ‚è≥ En attente |
| **RAM utilis√©e (master)** | üî¥ **[√Ä MESURER PENDANT EX√âCUTION]** GB | ‚è≥ En attente |
| **RAM utilis√©e (workers)** | üî¥ **[√Ä MESURER PENDANT EX√âCUTION]** GB | ‚è≥ En attente |
| **Dur√©e de vie du cluster** | üî¥ **[√Ä MESURER APR√àS TERMINAISON]** heures | ‚è≥ En attente |

**Comment mesurer :**
- Via CloudWatch Metrics (CPU, RAM, Network)
- Via Spark UI (onglet Executors)
- Via Ganglia (EMR monitoring natif)

---

## üí∞ M√©triques de Co√ªts AWS

### Estimation th√©orique (avant ex√©cution)

| Service | D√©tail | Dur√©e | Co√ªt unitaire (Spot) | Co√ªt total |
|---------|--------|-------|----------------------|------------|
| **EMR Master** | m6g.xlarge Spot | 2h | ~0,04‚Ç¨/h | ~0,08‚Ç¨ |
| **EMR Core (x2)** | m6g.large Spot | 2h | ~0,02‚Ç¨/h √ó 2 | ~0,08‚Ç¨ |
| **S3 Storage** | 2 GB stock√©s + r√©sultats (~500 MB) | 1 mois | ~0,023‚Ç¨/GB/mois | ~0,06‚Ç¨ |
| **S3 Transfert IN** | 2 GB upload | - | Gratuit | 0‚Ç¨ |
| **S3 Transfert OUT** | R√©sultats (~500 MB download) | - | Gratuit (m√™me r√©gion) | 0‚Ç¨ |
| **EMR Service Fee** | 10% du co√ªt instances | 2h | - | ~0,02‚Ç¨ |
| **TOTAL ESTIM√â** | | | | **~0,24‚Ç¨** |

**Note :** Cette estimation est tr√®s conservatrice. Le co√ªt r√©el pourrait √™tre l√©g√®rement sup√©rieur selon :
- Le temps d'ex√©cution r√©el
- Les transferts de donn√©es
- Les logs CloudWatch
- La consommation S3 r√©elle

### Co√ªts r√©els (apr√®s ex√©cution)

| Service | D√©tail | Dur√©e | Co√ªt unitaire | Co√ªt total |
|---------|--------|-------|---------------|------------|
| **EMR Master** | üî¥ **[√Ä RELEVER FACTURE AWS]** | üî¥ **[X]** h | üî¥ **[X]** ‚Ç¨/h | üî¥ **[X]** ‚Ç¨ |
| **EMR Core (x2)** | üî¥ **[√Ä RELEVER FACTURE AWS]** | üî¥ **[X]** h | üî¥ **[X]** ‚Ç¨/h | üî¥ **[X]** ‚Ç¨ |
| **S3 Storage** | üî¥ **[√Ä RELEVER FACTURE AWS]** | 1 mois | üî¥ **[X]** ‚Ç¨/GB | üî¥ **[X]** ‚Ç¨ |
| **S3 Requests** | üî¥ **[√Ä RELEVER FACTURE AWS]** | - | - | üî¥ **[X]** ‚Ç¨ |
| **S3 Transfert** | üî¥ **[√Ä RELEVER FACTURE AWS]** | - | - | üî¥ **[X]** ‚Ç¨ |
| **EMR Service Fee** | üî¥ **[√Ä RELEVER FACTURE AWS]** | - | - | üî¥ **[X]** ‚Ç¨ |
| **CloudWatch Logs** | üî¥ **[√Ä RELEVER FACTURE AWS]** | - | - | üî¥ **[X]** ‚Ç¨ |
| **Autres** | üî¥ **[√Ä RELEVER FACTURE AWS]** | - | - | üî¥ **[X]** ‚Ç¨ |
| **TOTAL R√âEL** | | | | üî¥ **[X,XX]** ‚Ç¨ |

**√âconomie vs budget :** üî¥ **[√Ä CALCULER]** % (Budget : 10‚Ç¨)

**Comment obtenir les co√ªts r√©els :**
1. Attendre 24-48h apr√®s terminaison du cluster (facturation diff√©r√©e)
2. Aller sur AWS Console ‚Üí Billing ‚Üí Bills
3. S√©lectionner le mois en cours
4. Filtrer par service : EMR, S3
5. Exporter le d√©tail en CSV
6. Remplir le tableau ci-dessus

---

## üìà M√©triques de Performance

### Comparaison th√©orique : Local vs EMR

| M√©trique | Local (1 machine) | EMR (1 master + 2 workers) | Gain |
|----------|-------------------|---------------------------|------|
| **vCPU disponibles** | 4-8 (laptop) | 8 (cluster) | ~1-2x |
| **RAM disponible** | 8-16 GB (laptop) | 32 GB (cluster) | ~2-4x |
| **Temps estim√©** | 6-8h | 1-2h | ~4-6x |
| **Scalabilit√©** | Non (RAM limit√©e) | Oui (ajout workers) | ‚àû |

**Note :** Le gain r√©el d√©pend du partitionnement Spark et de l'overhead r√©seau.

---

## üîí M√©triques de Conformit√© RGPD

| Crit√®re | Valeur | Validation |
|---------|--------|------------|
| **R√©gion stockage S3** | eu-west-1 (Ireland, UE) | ‚úÖ Conforme |
| **R√©gion cluster EMR** | eu-west-1 (Ireland, UE) | ‚úÖ Conforme |
| **Chiffrement S3 (repos)** | AES-256 | ‚úÖ Conforme |
| **Chiffrement S3 (transit)** | HTTPS/TLS | ‚úÖ Conforme |
| **Transferts hors UE** | 0 transfert | ‚úÖ Conforme |
| **Permissions IAM** | Principe du moindre privil√®ge | ‚úÖ Conforme |
| **Audit trail** | CloudTrail activ√© | ‚úÖ Conforme |

**R√©sultat :** 7/7 crit√®res conformes ‚Üí **100% conforme RGPD**

---

## üéØ M√©triques de Qualit√© des R√©sultats

### Features PCA

| M√©trique | Valeur | Statut |
|----------|--------|--------|
| **Dimensions r√©duites** | 256 | ‚úÖ Valid√© |
| **Variance conserv√©e** | üî¥ **[√Ä MESURER - ESTIMATION 90-95%]** % | ‚è≥ En attente |
| **Seuil minimum variance** | 90% | ‚úÖ Objectif fix√© |
| **Variance au-dessus seuil ?** | üî¥ **[OUI/NON √Ä VALIDER]** | ‚è≥ En attente |

### Format de sortie

| M√©trique | Valeur | Statut |
|----------|--------|--------|
| **Format fichiers** | Parquet | ‚úÖ Valid√© |
| **Compression** | Snappy (d√©faut Parquet) | ‚úÖ Valid√© |
| **Colonnes sauvegard√©es** | path, label, features_pca | ‚úÖ Valid√© |
| **Taille par vecteur** | ~1 KB (256 floats) | ‚úÖ Estim√© |

---

## üìã Checklist de collecte des m√©triques APR√àS AWS

### Pendant l'ex√©cution du notebook

- [ ] **Mesurer temps chargement S3** (cellule apr√®s `spark.read.format("image")`)
- [ ] **Mesurer temps preprocessing** (cellule apr√®s UDF preprocessing)
- [ ] **Mesurer taille mod√®le avant/apr√®s compression** (cellule broadcast)
- [ ] **Mesurer temps extraction features** (cellule apr√®s `extract_features()`)
- [ ] **Mesurer temps fit PCA** (cellule apr√®s `pca.fit()`)
- [ ] **Mesurer variance expliqu√©e PCA** (cellule apr√®s `pca_model.explainedVariance`)
- [ ] **G√©n√©rer graphique variance PCA** (cellule matplotlib)
- [ ] **Mesurer temps transform PCA** (cellule apr√®s `pca_model.transform()`)
- [ ] **Mesurer temps √©criture S3** (cellule apr√®s `.write.parquet()`)
- [ ] **Mesurer temps total** (d√©but premi√®re cellule ‚Üí fin derni√®re cellule)

### Apr√®s terminaison du cluster

- [ ] **V√©rifier taille fichiers Parquet sur S3** (Console S3 ou AWS CLI)
- [ ] **Relever dur√©e de vie du cluster** (Console EMR ‚Üí Cluster ‚Üí Timeline)
- [ ] **T√©l√©charger graphique variance PCA** depuis JupyterHub
- [ ] **Prendre screenshots** (Console EMR, JupyterHub, S3 bucket)

### 24-48h apr√®s terminaison

- [ ] **Consulter facture AWS** (Billing ‚Üí Bills)
- [ ] **Exporter d√©tails co√ªts** (CSV ou Excel)
- [ ] **Remplir tableau co√ªts r√©els** dans ce fichier
- [ ] **Calculer √©conomie vs budget** (10‚Ç¨ - co√ªt r√©el)

---

## üìä Tableau de synth√®se pour la pr√©sentation

**Ce tableau sera utilis√© dans le slide 17 de la pr√©sentation.**

| Cat√©gorie | M√©trique | Valeur |
|-----------|----------|--------|
| **Dataset** | Volume trait√© | 87 000 images (~2 GB) |
| **Pipeline** | Temps total ex√©cution | üî¥ **[X minutes]** |
| **Pipeline** | Dimensions | 1280 ‚Üí 256 (r√©duction 80%) |
| **Pipeline** | Variance PCA | üî¥ **[X%]** |
| **Cluster** | Configuration | 1 master + 2 workers (Graviton2) |
| **Cluster** | R√©gion | eu-west-1 (RGPD ‚úÖ) |
| **Co√ªts** | Total AWS | üî¥ **[X,XX‚Ç¨]** |
| **Co√ªts** | √âconomie vs budget | üî¥ **[X%]** (budget 10‚Ç¨) |
| **Conformit√©** | RGPD | ‚úÖ 100% conforme |
| **Qualit√©** | Pipeline | ‚úÖ Complet et fonctionnel |

---

**Date de finalisation pr√©vue :** Apr√®s ex√©cution Feature 4 (AWS Deployment)
**Responsable :** Maxime Nejad
