# Checklist Captures et M√©triques AWS - Feature 4

**Objectif :** S'assurer de capturer tous les screenshots et m√©triques n√©cessaires pour finaliser la pr√©sentation

**Quand :** Pendant et apr√®s l'ex√©cution de la Feature 4 (D√©ploiement AWS)

---

## üì∏ PHASE 1 : Screenshots √† capturer PENDANT l'ex√©cution

### 1.1 Console AWS - Cluster EMR actif

**Quand :** Juste apr√®s la cr√©ation du cluster (Phase 2 du guide AWS)

**O√π :** Console AWS ‚Üí EMR ‚Üí Clusters ‚Üí [votre cluster]

**Ce qui doit √™tre visible :**
- [ ] Nom du cluster
- [ ] Status : "Running" (vert)
- [ ] Master instance : m6g.xlarge
- [ ] Core instances : 2x m6g.large
- [ ] Applications : Spark, JupyterHub, TensorFlow
- [ ] R√©gion : eu-west-1
- [ ] Timeline avec date/heure de cr√©ation

**Comment capturer :**
- Mac : Cmd + Shift + 4 ‚Üí s√©lectionner zone
- Windows : Outil Capture d'√©cran

**Sauvegarder sous :**
```
docs/project/soutenance/visuels/screenshots/aws-emr-console.png
```

**Utilisation :** Slide 6 de la pr√©sentation

---

### 1.2 Console AWS - Configuration du cluster

**Quand :** Juste apr√®s cr√©ation cluster (optionnel, pour backup)

**O√π :** Console AWS ‚Üí EMR ‚Üí Clusters ‚Üí [cluster] ‚Üí Onglet "Hardware"

**Ce qui doit √™tre visible :**
- [ ] Liste des instances (master + 2 workers)
- [ ] Type d'instances (m6g.xlarge, m6g.large)
- [ ] Market type : Spot
- [ ] Availability Zone (eu-west-1a, eu-west-1b, etc.)

**Sauvegarder sous :**
```
docs/project/soutenance/visuels/screenshots/aws-emr-hardware.png
```

**Utilisation :** Backup, questions jury

---

### 1.3 JupyterHub - Notebook ouvert

**Quand :** Apr√®s connexion √† JupyterHub (Phase 3 du guide AWS)

**O√π :** JupyterHub EMR ‚Üí Notebook ouvert

**Ce qui doit √™tre visible :**
- [ ] Nom du notebook : "P8_Notebook_Linux_EMR_PySpark_V1.0.ipynb"
- [ ] Liste des cellules visibles
- [ ] Au moins une cellule ex√©cut√©e (kernel actif)
- [ ] Barre d'adresse JupyterHub visible (montre URL EMR)

**Sauvegarder sous :**
```
docs/project/soutenance/visuels/screenshots/jupyterhub-notebook.png
```

**Utilisation :** Slide 16

---

### 1.4 JupyterHub - Cellule PCA ex√©cut√©e

**Quand :** Pendant l'ex√©cution du notebook, apr√®s la cellule PCA

**O√π :** JupyterHub ‚Üí Cellule de code PCA avec output

**Ce qui doit √™tre visible :**
- [ ] Code de la PCA visible (pca.fit(), pca.transform())
- [ ] Output de la cellule montrant :
  - Variance expliqu√©e (ex: "Variance expliqu√©e : 95.2%")
  - Nombre de composantes (256)
  - Confirmation succ√®s
- [ ] Num√©ro de cellule visible (ex: In [14])

**Sauvegarder sous :**
```
docs/project/soutenance/visuels/screenshots/jupyterhub-pca-output.png
```

**Utilisation :** Slide 14, d√©monstration variance PCA

---

### 1.5 Bucket S3 - Dataset upload√©

**Quand :** Apr√®s upload du dataset (Phase 1 du guide AWS)

**O√π :** Console AWS ‚Üí S3 ‚Üí Buckets ‚Üí fruits-classification-p9-maxime ‚Üí Test/

**Ce qui doit √™tre visible :**
- [ ] Structure du bucket :
  - dataset/
    - Training/
      - Apple/ (folders de fruits)
      - Banana/
      - Orange/
      - etc.
- [ ] Nombre de dossiers (131 cat√©gories)
- [ ] Taille totale approximative (~2 GB)

**Sauvegarder sous :**
```
docs/project/soutenance/visuels/screenshots/s3-bucket-dataset.png
```

**Utilisation :** Slide 16

---

### 1.6 Bucket S3 - R√©sultats PCA g√©n√©r√©s

**Quand :** Apr√®s ex√©cution compl√®te du notebook (Phase 5 du guide AWS)

**O√π :** Console AWS ‚Üí S3 ‚Üí Buckets ‚Üí fruits-classification-p9-maxime ‚Üí Results/pca_output/

**Ce qui doit √™tre visible :**
- [ ] Dossier `Results/pca_output/`
- [ ] Fichiers Parquet list√©s (part-00000.parquet, part-00001.parquet, etc.)
- [ ] Taille des fichiers (en MB)
- [ ] Date de derni√®re modification (prouve que c'est r√©cent)
- [ ] Nombre de fichiers

**Sauvegarder sous :**
```
docs/project/soutenance/visuels/screenshots/s3-bucket-results-pca.png
```

**Utilisation :** Slide 16

---

## üìä PHASE 2 : M√©triques √† collecter PENDANT l'ex√©cution

### 2.1 M√©triques du pipeline (dans le notebook)

**O√π :** Ajouter des cellules de code dans le notebook pour mesurer

#### Temps de chargement S3

**Code √† ajouter apr√®s chargement :**
```python
import time

start_time = time.time()
df_images = spark.read.format("image") \
    .option("dropInvalid", True) \
    .load("s3://fruits-classification-p9-maxime/Test/")
df_images.cache()
count = df_images.count()
load_time = time.time() - start_time

print(f"‚úÖ Images charg√©es : {count}")
print(f"‚è±Ô∏è Temps de chargement : {load_time:.2f} secondes ({load_time/60:.2f} minutes)")

# NOTER CES VALEURS IMM√âDIATEMENT
```

**Valeurs √† noter :**
- [ ] Nombre d'images charg√©es : ___________
- [ ] Temps de chargement : ___________ minutes

---

#### Temps d'extraction de features

**Code √† ajouter apr√®s extraction :**
```python
start_time = time.time()
df_features = extract_features(df_preprocessed, model_broadcast)
df_features.cache()
count = df_features.count()
extraction_time = time.time() - start_time

print(f"‚úÖ Features extraites : {count}")
print(f"‚è±Ô∏è Temps d'extraction : {extraction_time:.2f} secondes ({extraction_time/60:.2f} minutes)")
```

**Valeurs √† noter :**
- [ ] Nombre de features extraites : ___________
- [ ] Temps d'extraction : ___________ minutes

---

#### Variance PCA (CRITIQUE)

**Code √† ajouter apr√®s PCA :**
```python
from pyspark.ml.feature import PCA

pca = PCA(k=256, inputCol="features_vector", outputCol="features_pca")

# Fit
start_fit = time.time()
pca_model = pca.fit(df_vectorized)
fit_time = time.time() - start_fit

# Variance expliqu√©e
variance_expliquee = sum(pca_model.explainedVariance[:256])

print(f"‚úÖ Variance expliqu√©e : {variance_expliquee:.2%}")
print(f"‚è±Ô∏è Temps de fit PCA : {fit_time:.2f} secondes ({fit_time/60:.2f} minutes)")

# Transform
start_transform = time.time()
df_pca = pca_model.transform(df_vectorized)
df_pca.cache()
count = df_pca.count()
transform_time = time.time() - start_transform

print(f"‚úÖ Vecteurs PCA g√©n√©r√©s : {count}")
print(f"‚è±Ô∏è Temps de transform : {transform_time:.2f} secondes ({transform_time/60:.2f} minutes)")
```

**Valeurs √† noter :**
- [ ] Variance expliqu√©e : ___________ %
- [ ] Temps de fit : ___________ minutes
- [ ] Temps de transform : ___________ minutes
- [ ] Vecteurs PCA g√©n√©r√©s : ___________

---

#### Temps de sauvegarde S3

**Code √† ajouter apr√®s sauvegarde :**
```python
start_time = time.time()
df_pca.select("path", "label", "features_pca") \
    .write \
    .mode("overwrite") \
    .parquet("s3://fruits-classification-p9-maxime/Results/pca_output/")
write_time = time.time() - start_time

print(f"‚úÖ R√©sultats sauvegard√©s")
print(f"‚è±Ô∏è Temps d'√©criture : {write_time:.2f} secondes ({write_time/60:.2f} minutes)")
```

**Valeurs √† noter :**
- [ ] Temps d'√©criture : ___________ minutes

---

#### Temps total du pipeline

**Code √† ajouter √† la fin du notebook :**
```python
total_time = load_time + extraction_time + fit_time + transform_time + write_time

print(f"\n{'='*60}")
print(f"‚è±Ô∏è TEMPS TOTAL DU PIPELINE")
print(f"{'='*60}")
print(f"Chargement S3       : {load_time/60:>6.2f} min")
print(f"Extraction features : {extraction_time/60:>6.2f} min")
print(f"PCA fit             : {fit_time/60:>6.2f} min")
print(f"PCA transform       : {transform_time/60:>6.2f} min")
print(f"Sauvegarde S3       : {write_time/60:>6.2f} min")
print(f"{'='*60}")
print(f"TOTAL               : {total_time/60:>6.2f} min")
print(f"{'='*60}")
print(f"\n‚úÖ Pipeline complet ex√©cut√© avec succ√®s !")
```

**Valeur √† noter :**
- [ ] Temps total : ___________ minutes

---

### 2.2 Graphique variance PCA (CRITIQUE)

**Code √† ajouter dans une nouvelle cellule apr√®s PCA :**

```python
import matplotlib.pyplot as plt

# R√©cup√©rer variance
variance = pca_model.explainedVariance
cumulative_variance = []
total = 0
for v in variance:
    total += v
    cumulative_variance.append(total)

# Cr√©er graphique
plt.figure(figsize=(12, 7))
plt.plot(range(1, len(cumulative_variance)+1), cumulative_variance,
         linewidth=2, color='#1E3A8A', label='Variance cumulative')
plt.axhline(y=0.9, color='red', linestyle='--', linewidth=2,
            label='Seuil 90%')
plt.xlabel('Nombre de composantes principales', fontsize=14, fontweight='bold')
plt.ylabel('Variance expliqu√©e cumulative', fontsize=14, fontweight='bold')
plt.title('Variance Expliqu√©e par PCA - Fruits Classification',
          fontsize=16, fontweight='bold')
plt.legend(fontsize=12, loc='lower right')
plt.grid(True, alpha=0.3)
plt.tight_layout()

# Sauvegarder localement dans JupyterHub
plt.savefig('variance_pca.png', dpi=300, bbox_inches='tight')
plt.show()

print(f"‚úÖ Graphique sauvegard√© : variance_pca.png")
print(f"üìä Variance √† 256 composantes : {cumulative_variance[255]:.2%}")
```

**Actions apr√®s ex√©cution :**
- [ ] V√©rifier que le graphique s'affiche correctement
- [ ] Noter la variance √† 256 composantes : ___________ %
- [ ] T√©l√©charger le fichier `variance_pca.png` depuis JupyterHub :
  - Clic droit sur fichier ‚Üí Download
  - Sauvegarder dans `docs/project/soutenance/visuels/`

**Utilisation :** Slide 14

---

## üí∞ PHASE 3 : Co√ªts AWS (24-48h APR√àS l'ex√©cution)

### 3.1 Relever la dur√©e du cluster

**Quand :** Apr√®s terminaison du cluster

**O√π :** Console AWS ‚Üí EMR ‚Üí Clusters ‚Üí [cluster] ‚Üí Timeline

**Ce qui doit √™tre visible :**
- [ ] Heure de cr√©ation
- [ ] Heure de terminaison
- [ ] Dur√©e totale (heures:minutes)

**Valeur √† noter :**
- [ ] Dur√©e de vie du cluster : ___________ heures

---

### 3.2 Consulter la facture AWS

**Quand :** 24-48h apr√®s terminaison du cluster

**O√π :** Console AWS ‚Üí Billing ‚Üí Bills ‚Üí Mois en cours

**Actions :**
1. Aller sur AWS Billing Dashboard
2. S√©lectionner le mois en cours
3. Rechercher :
   - Amazon EMR
   - Amazon S3
   - AWS Data Transfer
4. Noter les co√ªts d√©taill√©s

**Tableau √† remplir :**

| Service | D√©tail | Dur√©e | Co√ªt unitaire | Co√ªt total |
|---------|--------|-------|---------------|------------|
| EMR Master | m6g.xlarge Spot | _____ h | _____ ‚Ç¨/h | _____ ‚Ç¨ |
| EMR Core (x2) | m6g.large Spot | _____ h | _____ ‚Ç¨/h | _____ ‚Ç¨ |
| EMR Service Fee | 10% instances | - | - | _____ ‚Ç¨ |
| S3 Storage | _____ GB | 1 mois | _____ ‚Ç¨/GB | _____ ‚Ç¨ |
| S3 Requests | _____ requ√™tes | - | - | _____ ‚Ç¨ |
| S3 Transfer | _____ GB | - | - | _____ ‚Ç¨ |
| CloudWatch Logs | _____ GB | - | - | _____ ‚Ç¨ |
| Autres | _____ | - | - | _____ ‚Ç¨ |
| **TOTAL** | | | | **_____ ‚Ç¨** |

**Actions apr√®s collecte :**
- [ ] Remplir le tableau dans `metriques.md`
- [ ] Calculer √©conomie : (10‚Ç¨ - co√ªt r√©el) / 10‚Ç¨ √ó 100 = _____ %
- [ ] Mettre √† jour slide 9 de la pr√©sentation

---

### 3.3 Cr√©er tableau co√ªts pour la pr√©sentation

**O√π :** PowerPoint, Slide 9

**Contenu :**
Copier les valeurs du tableau ci-dessus dans un tableau PowerPoint format√©.

**Instructions :**
1. Ins√©rer ‚Üí Tableau dans slide 9
2. Remplir avec valeurs r√©elles
3. Mettre en gras la ligne TOTAL
4. Ajouter note en bas : "√âconomie : X% vs budget 10‚Ç¨"

---

## üìã PHASE 4 : Finalisation de la pr√©sentation

### 4.1 Remplacer tous les placeholders

**Fichiers √† mettre √† jour :**

1. **metriques.md**
   - [ ] Remplir tous les champs marqu√©s üî¥ [MANQUANT]
   - [ ] V√©rifier coh√©rence des donn√©es

2. **PowerPoint (presentation.pptx)**
   - [ ] Slide 6 : Ins√©rer screenshot Console EMR
   - [ ] Slide 9 : Ins√©rer tableau co√ªts r√©els
   - [ ] Slide 10 : Ins√©rer temps total ex√©cution
   - [ ] Slide 14 : Ins√©rer graphique variance PCA + variance r√©elle
   - [ ] Slide 16 : Ins√©rer 3 screenshots (Console, JupyterHub, S3)
   - [ ] Slide 17 : Remplir toutes les m√©triques

3. **V√©rifier coh√©rence**
   - [ ] Tous les chiffres sont identiques dans tous les fichiers
   - [ ] Aucun placeholder rouge ne reste
   - [ ] Screenshots en haute qualit√© (lisibles)

---

### 4.2 Tests finaux

- [ ] Relire pr√©sentation slide par slide
- [ ] V√©rifier lisibilit√© screenshots (zoom pour tester)
- [ ] Tester timing : r√©p√©tition chronom√®tre en main
- [ ] V√©rifier notes de pr√©sentation

---

## üéØ Checklist R√©capitulative Globale

### Screenshots (6)

- [ ] **1. Console AWS - Cluster EMR actif** ‚Üí Slide 6
- [ ] **2. Console AWS - Hardware cluster** (backup)
- [ ] **3. JupyterHub - Notebook ouvert** ‚Üí Slide 16
- [ ] **4. JupyterHub - Cellule PCA output** ‚Üí Slide 14
- [ ] **5. S3 - Dataset upload√©** ‚Üí Slide 16
- [ ] **6. S3 - R√©sultats PCA** ‚Üí Slide 16

### M√©triques (9)

- [ ] **1. Temps chargement S3**
- [ ] **2. Temps extraction features**
- [ ] **3. Variance PCA** (CRITIQUE) ‚Üí Slides 14, 17
- [ ] **4. Temps fit PCA**
- [ ] **5. Temps transform PCA**
- [ ] **6. Temps sauvegarde S3**
- [ ] **7. Temps total pipeline** ‚Üí Slides 10, 17
- [ ] **8. Dur√©e cluster**
- [ ] **9. Co√ªts AWS r√©els** ‚Üí Slides 9, 17

### Visuels (1)

- [ ] **Graphique variance PCA** ‚Üí Slide 14

### Tableau (1)

- [ ] **Tableau co√ªts AWS d√©taill√©** ‚Üí Slide 9

---

## üí° Conseils Pratiques

### Pendant l'ex√©cution

1. **Prendre les screenshots au fur et √† mesure**
   - Ne pas attendre la fin pour tout capturer
   - Risque : cluster termin√© = plus de screenshots possibles

2. **Noter les m√©triques imm√©diatement**
   - Cr√©er un fichier texte temporaire
   - Copier/coller les outputs du notebook

3. **Sauvegarder r√©guli√®rement**
   - Screenshots dans le bon dossier imm√©diatement
   - Backup sur cloud (Drive, Dropbox) recommand√©

### Si quelque chose √©choue

**Si cluster s'arr√™te avant screenshots :**
‚Üí Les logs EMR restent disponibles pendant 7 jours
‚Üí Consulter CloudWatch Logs pour r√©cup√©rer certaines m√©triques

**Si screenshot rat√© :**
‚Üí Possibilit√© de relancer cluster bri√®vement juste pour screenshots
‚Üí Co√ªt minimal (~0,10‚Ç¨ pour 15 min)

**Si m√©trique non mesur√©e :**
‚Üí Estimer en extrapolant depuis tests locaux
‚Üí Mentionner que c'est une estimation dans la pr√©sentation

---

## üìû Support

**Si probl√®me pendant ex√©cution :**
1. Consulter `docs/project/guides/aws-setup-guide.md` section Troubleshooting
2. V√©rifier logs CloudWatch
3. V√©rifier Spark UI (port 8088 sur master)

**Si doute sur m√©trique :**
‚Üí Consultez `metriques.md` qui contient les codes Python pour mesurer

---

**Temps total estim√© pour collecte :** 15-20 minutes pendant ex√©cution + 15 min apr√®s
**Bonne ex√©cution AWS ! üöÄ**
